++++ /usr/local/src/analytic-libs/profile.sh 2.1 2.11 2.7
+++ local 'profiledata=EXTRA_CLASSPATH='\''/usr/local/src/analytic-libs/common/*:/usr/local/src/analytic-libs/spark-2.1/*'\'' EXTRA_PYTHONPATH='\''/usr/local/src/analytic-libs/spark-2.1/python-2.7:/usr/local/src/analytic-libs/spark-2.1/python:/usr/local/src/analytic-libs/python'\'''
+++ eval local 'EXTRA_CLASSPATH='\''/usr/local/src/analytic-libs/common/*:/usr/local/src/analytic-libs/spark-2.1/*'\''' 'EXTRA_PYTHONPATH='\''/usr/local/src/analytic-libs/spark-2.1/python-2.7:/usr/local/src/analytic-libs/spark-2.1/python:/usr/local/src/analytic-libs/python'\'''
++++ local 'EXTRA_CLASSPATH=/usr/local/src/analytic-libs/common/*:/usr/local/src/analytic-libs/spark-2.1/*' EXTRA_PYTHONPATH=/usr/local/src/analytic-libs/spark-2.1/python-2.7:/usr/local/src/analytic-libs/spark-2.1/python:/usr/local/src/analytic-libs/python
+++ [[ -n /usr/local/src/analytic-libs/common/*:/usr/local/src/analytic-libs/spark-2.1/* ]]
+++ export 'SPARK_DIST_CLASSPATH+=:/usr/local/src/analytic-libs/common/*:/usr/local/src/analytic-libs/spark-2.1/*'
+++ SPARK_DIST_CLASSPATH+=':/usr/local/src/analytic-libs/common/*:/usr/local/src/analytic-libs/spark-2.1/*'
+++ [[ -n /usr/local/src/analytic-libs/spark-2.1/python-2.7:/usr/local/src/analytic-libs/spark-2.1/python:/usr/local/src/analytic-libs/python ]]
+++ export PYTHONPATH+=:/usr/local/src/analytic-libs/spark-2.1/python-2.7:/usr/local/src/analytic-libs/spark-2.1/python:/usr/local/src/analytic-libs/python
+++ PYTHONPATH+=:/usr/local/src/analytic-libs/spark-2.1/python-2.7:/usr/local/src/analytic-libs/spark-2.1/python:/usr/local/src/analytic-libs/python
+++ [[ /usr/local/src/analytic-libs/profile.sh == */wml-libs* ]]
+++ set +x
++++ /usr/local/src/wml-libs/profile.sh 2.1 2.11 2.7
+++ local 'profiledata=EXTRA_CLASSPATH='\''/usr/local/src/wml-libs.v30/jars/*:/usr/local/src/wml-libs.v30/spark-2.1/jars/*:/usr/local/src/wml-libs.v30/spark-2.1/dataconnector-dw-2.1/*'\'' EXTRA_PYTHONPATH='\''/usr/local/src/wml-libs.v30/python-2.7:/usr/local/src/wml-libs.v30/spark-2.1/python-2.7'\'' TAM_DIR='\''/usr/local/src/wml-libs.v30/tam'\'''
+++ eval local 'EXTRA_CLASSPATH='\''/usr/local/src/wml-libs.v30/jars/*:/usr/local/src/wml-libs.v30/spark-2.1/jars/*:/usr/local/src/wml-libs.v30/spark-2.1/dataconnector-dw-2.1/*'\''' 'EXTRA_PYTHONPATH='\''/usr/local/src/wml-libs.v30/python-2.7:/usr/local/src/wml-libs.v30/spark-2.1/python-2.7'\''' 'TAM_DIR='\''/usr/local/src/wml-libs.v30/tam'\'''
++++ local 'EXTRA_CLASSPATH=/usr/local/src/wml-libs.v30/jars/*:/usr/local/src/wml-libs.v30/spark-2.1/jars/*:/usr/local/src/wml-libs.v30/spark-2.1/dataconnector-dw-2.1/*' EXTRA_PYTHONPATH=/usr/local/src/wml-libs.v30/python-2.7:/usr/local/src/wml-libs.v30/spark-2.1/python-2.7 TAM_DIR=/usr/local/src/wml-libs.v30/tam
+++ [[ -n /usr/local/src/wml-libs.v30/jars/*:/usr/local/src/wml-libs.v30/spark-2.1/jars/*:/usr/local/src/wml-libs.v30/spark-2.1/dataconnector-dw-2.1/* ]]
+++ export 'SPARK_DIST_CLASSPATH+=:/usr/local/src/wml-libs.v30/jars/*:/usr/local/src/wml-libs.v30/spark-2.1/jars/*:/usr/local/src/wml-libs.v30/spark-2.1/dataconnector-dw-2.1/*'
+++ SPARK_DIST_CLASSPATH+=':/usr/local/src/wml-libs.v30/jars/*:/usr/local/src/wml-libs.v30/spark-2.1/jars/*:/usr/local/src/wml-libs.v30/spark-2.1/dataconnector-dw-2.1/*'
+++ [[ -n /usr/local/src/wml-libs.v30/python-2.7:/usr/local/src/wml-libs.v30/spark-2.1/python-2.7 ]]
+++ export PYTHONPATH+=:/usr/local/src/wml-libs.v30/python-2.7:/usr/local/src/wml-libs.v30/spark-2.1/python-2.7
+++ PYTHONPATH+=:/usr/local/src/wml-libs.v30/python-2.7:/usr/local/src/wml-libs.v30/spark-2.1/python-2.7
+++ [[ /usr/local/src/wml-libs/profile.sh == */wml-libs* ]]
+++ [[ -n /usr/local/src/wml-libs.v30/tam ]]
+++ export NGWB_TAM_FILE_LOCATION=/usr/local/src/wml-libs.v30/tam
+++ NGWB_TAM_FILE_LOCATION=/usr/local/src/wml-libs.v30/tam
+++ set +x
Spark Command: /usr/local/src/spark21master/ibm-java-x86_64-80/bin/java -cp /usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/ego/spark-launcher_2.11-2.1.2.jar:/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/ego/spark-network-shuffle_2.11-2.1.2.jar:/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/ego/gson-2.2.4.jar:/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/ego/guava-14.0.1.jar:/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/ego/Java-WebSocket-1.3.0.jar:/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/ego/spark-ego_2.11-2.1.2.jar:/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/ego/spark-network-common_2.11-2.1.2.jar:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/thirdparty/avro-1.8.0.jar:/usr/local/src/spark21master/spark/profile/batch/:/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/jars/*:/usr/local/src/analytic-libs/common/*:/usr/local/src/analytic-libs/spark-2.1/*:/usr/local/src/wml-libs.v30/jars/*:/usr/local/src/wml-libs.v30/spark-2.1/jars/*:/usr/local/src/wml-libs.v30/spark-2.1/dataconnector-dw-2.1/*:/gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/data/libs/:/gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/data/libs/*:/gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/data/libs/scala-2.11:/gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/data/libs/scala-2.11/*:/usr/local/src/dataconnector-stocator/spark-2.0.0/libs/*:/usr/local/src/dataconnector-s3-2.0/spark-2.0.0/libs/*:/usr/local/src/dataconnector-cloudant-2.0/spark-2.0.0/libs/*:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/*:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jdbc/lib/*:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/thirdparty/*:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/libs/*:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/thirdparty/aws/*:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/config/:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/FaspStreamSDK/lib/*:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/JISPlugins/*:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/branded_jdbc/lib/*:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/ASBServer/apps/lib/iis/*/*:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/connectors/*/*:/usr/local/src/event-stream-2.0/spark-2.0.0/libs/*:/usr/local/src/dataconnector-db2/*:/usr/local/src/datasource-idax/* -Dspark.executor.extraClassPath=/gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/data/libs/*: -Dspark.service.hashed_tenant_id=drqZ3lx0wZAjq+1tGx+RTTMzS35bUrX0bePBKA== -Dspark.eventLog.enabled=true -Dspark.service.plan_name=ibm.SparkService.PayGoPersonal -Dspark.authenticate.secret=.secret -Dspark.ego.authenticate.tenantSecret.pathPrefix=/gpfs/fs01/user -Dspark.service.spark_version=2.1 -Dspark.driver.extraLibraryPath=/gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/data/libs/*: -Dspark.authenticate.enableSaslEncryption=true -Dspark.jars=/gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/data/0ae1e90fd7d8fdb11f6b313afed597ba2feaa0ea/simpleloanvalidationsparkrunner-1.0-SNAPSHOT-withodmrt.jar -Dspark.eventLog.dir=/gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/events -Dspark.master=spark://yp-spark-dal09-env5-0009:7089 -Dspark.executor.extraLibraryPath=/gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/data/libs/*: -Dspark.driver.extraClassPath=/gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/data/libs/*: -Dspark.driver.extraJavaOptions=-Xdump:tool:events=excessivegc,exec=kill -9 %pid -Dspark.executor.memory=1024m -Dspark.io.encryption.enabled=true -Dspark.ego.authenticate.tenantSecret.filename=.secret -Dspark.app.name=“loan-validation” -Dspark.network.sasl.serverAlwaysEncrypt=true -Dspark.driver.maxResultSize=1210M -Dspark.authenticate=true -Dspark.files.useFetchCache=false -Xdump:tool:events=excessivegc,exec=kill -9 %pid -Dspark.shuffle.service.port=7342 -Xmx1512m org.apache.spark.deploy.ego.EGOClusterDriverWrapper {{WORKER_URL}} /gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/data/0ae1e90fd7d8fdb11f6b313afed597ba2feaa0ea/simpleloanvalidationsparkrunner-1.0-SNAPSHOT-withodmrt.jar com.ibm.decisions.spark.loanvalidation.LoanValidationSparkRunner --inputgen 1000 --output loanvalidation-decisions-1K.json
========================================
log4j:ERROR Could not find value for key log4j.appender.FILE
log4j:ERROR Could not instantiate appender named "FILE".
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/src/wml-libs.v30/spark-2.0/jars/tika-app-2.0-1.14.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/src/wml-libs.v30/spark-2.0/jars/ml-event-client-scala-library-0.1.55-201709150512-allinone.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/thirdparty/slf4j-simple-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
18/07/19 16:10:59 INFO deploy.ego.EGOClusterDriverWrapper: Started daemon with process name: 41777@yp-spark-dal09-env5-0031
18/07/19 16:10:59 INFO spark.util.SignalUtils: Registered signal handler for TERM
18/07/19 16:10:59 INFO spark.util.SignalUtils: Registered signal handler for HUP
18/07/19 16:10:59 INFO spark.util.SignalUtils: Registered signal handler for INT
18/07/19 16:10:59 WARN hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/07/19 16:11:00 INFO apache.spark.SecurityManager: Changing view acls to: sb1f-e2fb2aec88783d-178f40bd326e
18/07/19 16:11:00 INFO apache.spark.SecurityManager: Changing modify acls to: sb1f-e2fb2aec88783d-178f40bd326e
18/07/19 16:11:00 INFO apache.spark.SecurityManager: Changing view acls groups to: 
18/07/19 16:11:00 INFO apache.spark.SecurityManager: Changing modify acls groups to: 
18/07/19 16:11:00 INFO apache.spark.SecurityManager: SecurityManager: authentication enabled; ui acls disabled; users  with view permissions: Set(sb1f-e2fb2aec88783d-178f40bd326e); groups with view permissions: Set(); users  with modify permissions: Set(sb1f-e2fb2aec88783d-178f40bd326e); groups with modify permissions: Set()
18/07/19 16:11:00 INFO spark.util.Utils: Successfully started service 'EGOClusterDriverWrapper-driver-20180719161057-0077-67a4cde6-0a2c-4032-a82a-d8bbbf24a9b3' on port 34667.
18/07/19 16:11:01 INFO network.client.TransportClientFactory: Successfully created connection to yp-spark-dal09-env5-0009/10.142.16.72:7089 after 693 ms (660 ms spent in bootstraps)
18/07/19 16:11:01 INFO apache.spark.SecurityManager: Changing view acls to: sb1f-e2fb2aec88783d-178f40bd326e
18/07/19 16:11:01 INFO apache.spark.SecurityManager: Changing modify acls to: sb1f-e2fb2aec88783d-178f40bd326e
18/07/19 16:11:01 INFO apache.spark.SecurityManager: Changing view acls groups to: 
18/07/19 16:11:01 INFO apache.spark.SecurityManager: Changing modify acls groups to: 
18/07/19 16:11:01 INFO apache.spark.SecurityManager: SecurityManager: authentication enabled; ui acls disabled; users  with view permissions: Set(sb1f-e2fb2aec88783d-178f40bd326e); groups with view permissions: Set(); users  with modify permissions: Set(sb1f-e2fb2aec88783d-178f40bd326e); groups with modify permissions: Set()
18/07/19 16:11:01 INFO deploy.ego.EGOClusterDriverWrapper: Fetching jar file from /gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/data/0ae1e90fd7d8fdb11f6b313afed597ba2feaa0ea/simpleloanvalidationsparkrunner-1.0-SNAPSHOT-withodmrt.jar to /tmp/spark-21-ego-master/work/spark-driver-4c56a1d1-30c1-4bfc-8e99-e50cfc564fd0/simpleloanvalidationsparkrunner-1.0-SNAPSHOT-withodmrt.jar
18/07/19 16:11:01 INFO spark.util.Utils: Copying /gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/data/0ae1e90fd7d8fdb11f6b313afed597ba2feaa0ea/simpleloanvalidationsparkrunner-1.0-SNAPSHOT-withodmrt.jar to /tmp/spark-21-ego-master/work/spark-driver-4c56a1d1-30c1-4bfc-8e99-e50cfc564fd0/simpleloanvalidationsparkrunner-1.0-SNAPSHOT-withodmrt.jar
18/07/19 16:11:01 INFO deploy.ego.EGOClusterDriverWrapper: Starting the user JAR in a separate Thread
18/07/19 16:11:01 INFO deploy.ego.EGOClusterDriverWrapper: Waiting for spark context initialization ... 0
18/07/19 16:11:01 INFO apache.spark.SparkContext: Running Spark version 2.1.2
18/07/19 16:11:01 INFO apache.spark.SecurityManager: Changing view acls to: sb1f-e2fb2aec88783d-178f40bd326e
18/07/19 16:11:01 INFO apache.spark.SecurityManager: Changing modify acls to: sb1f-e2fb2aec88783d-178f40bd326e
18/07/19 16:11:01 INFO apache.spark.SecurityManager: Changing view acls groups to: 
18/07/19 16:11:01 INFO apache.spark.SecurityManager: Changing modify acls groups to: 
18/07/19 16:11:01 INFO apache.spark.SecurityManager: SecurityManager: authentication enabled; ui acls disabled; users  with view permissions: Set(sb1f-e2fb2aec88783d-178f40bd326e); groups with view permissions: Set(); users  with modify permissions: Set(sb1f-e2fb2aec88783d-178f40bd326e); groups with modify permissions: Set()
18/07/19 16:11:01 INFO spark.util.Utils: Successfully started service 'sparkDriver' on port 38741.
18/07/19 16:11:01 INFO apache.spark.SparkEnv: Registering MapOutputTracker
18/07/19 16:11:01 INFO apache.spark.SparkEnv: Registering BlockManagerMaster
18/07/19 16:11:01 INFO spark.storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/07/19 16:11:01 INFO spark.storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/07/19 16:11:01 INFO storage.memory.MemoryStore: MemoryStore started with capacity 727.2 MB
18/07/19 16:11:01 INFO apache.spark.SparkEnv: Registering OutputCommitCoordinator
18/07/19 16:11:02 INFO jetty.util.log: Logging initialized @3537ms
18/07/19 16:11:02 INFO jetty.server.Server: jetty-9.2.z-SNAPSHOT
18/07/19 16:11:02 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-2591aade{/login,null,AVAILABLE,@Spark}
18/07/19 16:11:02 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5aa88675{/logout,null,AVAILABLE,@Spark}
18/07/19 16:11:02 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@48253b4f{/jobs,null,AVAILABLE,@Spark}
18/07/19 16:11:02 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-18e7378d{/jobs/json,null,AVAILABLE,@Spark}
18/07/19 16:11:02 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-459f43a8{/jobs/job,null,AVAILABLE,@Spark}
18/07/19 16:11:02 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@579d23de{/jobs/job/json,null,AVAILABLE,@Spark}
18/07/19 16:11:02 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@e96bfa5{/stages,null,AVAILABLE,@Spark}
18/07/19 16:11:02 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-307f0b1{/stages/json,null,AVAILABLE,@Spark}
18/07/19 16:11:02 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-27721e2{/stages/stage,null,AVAILABLE,@Spark}
18/07/19 16:11:02 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@204628a0{/stages/stage/json,null,AVAILABLE,@Spark}
18/07/19 16:11:02 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7c5ab9df{/stages/pool,null,AVAILABLE,@Spark}
18/07/19 16:11:02 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@63ed6043{/stages/pool/json,null,AVAILABLE,@Spark}
18/07/19 16:11:02 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-6e0b3f61{/storage,null,AVAILABLE,@Spark}
18/07/19 16:11:02 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3ca24877{/storage/json,null,AVAILABLE,@Spark}
18/07/19 16:11:02 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7e22f118{/storage/rdd,null,AVAILABLE,@Spark}
18/07/19 16:11:02 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-4c11a7fb{/storage/rdd/json,null,AVAILABLE,@Spark}
18/07/19 16:11:02 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-393d7a34{/environment,null,AVAILABLE,@Spark}
18/07/19 16:11:02 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-12c030a9{/environment/json,null,AVAILABLE,@Spark}
18/07/19 16:11:02 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-f0fb976{/executors,null,AVAILABLE,@Spark}
18/07/19 16:11:02 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-1c73e1f8{/executors/json,null,AVAILABLE,@Spark}
18/07/19 16:11:02 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4b882e56{/executors/threadDump,null,AVAILABLE,@Spark}
18/07/19 16:11:02 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@36cf6ca7{/executors/threadDump/json,null,AVAILABLE,@Spark}
18/07/19 16:11:02 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-3579e917{/static,null,AVAILABLE,@Spark}
18/07/19 16:11:02 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-2a73fc09{/,null,AVAILABLE,@Spark}
18/07/19 16:11:02 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-38256129{/api,null,AVAILABLE,@Spark}
18/07/19 16:11:02 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-5dded2d1{/jobs/job/kill,null,AVAILABLE,@Spark}
18/07/19 16:11:02 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-5ef33774{/stages/stage/kill,null,AVAILABLE,@Spark}
18/07/19 16:11:02 INFO jetty.server.ServerConnector: Started Spark@915b49f2{HTTP/1.1}{0.0.0.0:42832}
18/07/19 16:11:02 INFO jetty.server.Server: Started @3693ms
18/07/19 16:11:02 INFO spark.util.Utils: Successfully started service 'SparkUI' on port 42832.
18/07/19 16:11:02 INFO spark.ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://10.142.16.83:42832
18/07/19 16:11:02 INFO apache.spark.SparkContext: Added JAR /gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/data/0ae1e90fd7d8fdb11f6b313afed597ba2feaa0ea/simpleloanvalidationsparkrunner-1.0-SNAPSHOT-withodmrt.jar at spark://10.142.16.83:38741/jars/simpleloanvalidationsparkrunner-1.0-SNAPSHOT-withodmrt.jar with timestamp 1532034662225
18/07/19 16:11:02 INFO spark.util.EGOSparkDockerConfig: Executor Container Type is 'normal' from local configuration file.
18/07/19 16:11:02 INFO spark.util.EGOSparkDockerConfig: Driver Container Type is 'normal' from local configuration file.
18/07/19 16:11:02 INFO spark.util.EGOSparkDockerConfig: spark-ego-docker.conf will not be parsed as docker is not defined as any container type.
18/07/19 16:11:02 INFO cluster.ego.EGOFineGrainedSchedulerBackend: setting reserve=0, priority=1, limit=2147483647, gpuLimit=2147483647, master=[Ljava.lang.String;@140f19f7
18/07/19 16:11:02 INFO client.ego.EGOAppClient$ClientEndpoint: Connecting to master spark://yp-spark-dal09-env5-0009:7089...
18/07/19 16:11:02 INFO network.client.TransportClientFactory: Successfully created connection to yp-spark-dal09-env5-0009/10.142.16.72:7089 after 56 ms (55 ms spent in bootstraps)
18/07/19 16:11:02 INFO network.client.TransportClientFactory: Successfully created connection to /10.142.16.83:34667 after 85 ms (84 ms spent in bootstraps)
18/07/19 16:11:02 INFO cluster.ego.EGOFineGrainedSchedulerBackend: Connected to Spark cluster with app ID app-20180719161102-0067-dc6822d0-75cf-48c1-bfbd-4f99665edb12
18/07/19 16:11:02 INFO cluster.ego.EGOFineGrainedSchedulerBackend: Application registered successfully as app-20180719161102-0067-dc6822d0-75cf-48c1-bfbd-4f99665edb12, executor Container type is normal
18/07/19 16:11:02 INFO spark.storage.DiskBlockManager: Init the driver local dir
18/07/19 16:11:02 INFO spark.storage.DiskBlockManager: Created local directory at /tmp/spark-21-ego-master/work/blockmgr-1121d505-bda3-48f0-8fe3-acda3ecfa9d6
18/07/19 16:11:02 INFO spark.util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 35848.
18/07/19 16:11:02 INFO network.netty.NettyBlockTransferService: Server created on 10.142.16.83:35848
18/07/19 16:11:02 INFO spark.storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/07/19 16:11:02 INFO spark.storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.142.16.83, 35848, None)
18/07/19 16:11:02 INFO spark.storage.BlockManagerMasterEndpoint: Registering block manager 10.142.16.83:35848 with 727.2 MB RAM, BlockManagerId(driver, 10.142.16.83, 35848, None)
18/07/19 16:11:02 INFO spark.storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.142.16.83, 35848, None)
18/07/19 16:11:02 INFO spark.storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.142.16.83, 35848, None)
18/07/19 16:11:02 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-25b9dd69{/metrics/json,null,AVAILABLE,@Spark}
18/07/19 16:11:02 INFO spark.scheduler.EventLoggingListener: Logging events to file:/gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/events/app-20180719161102-0067-dc6822d0-75cf-48c1-bfbd-4f99665edb12
18/07/19 16:11:02 INFO cluster.ego.EGODeployScheduler: Spark context initialized.
18/07/19 16:11:03 INFO apache.spark.SparkContext: Starting job: count at LoanValidationSparkRunner.java:267
18/07/19 16:11:03 INFO spark.scheduler.DAGScheduler: Got job 0 (count at LoanValidationSparkRunner.java:267) with 2 output partitions
18/07/19 16:11:03 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 0 (count at LoanValidationSparkRunner.java:267)
18/07/19 16:11:03 INFO spark.scheduler.DAGScheduler: Parents of final stage: List()
18/07/19 16:11:03 INFO spark.scheduler.DAGScheduler: Missing parents: List()
18/07/19 16:11:03 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 0 (ParallelCollectionRDD[0] at parallelize at RequestGenerator.java:158), which has no missing parents
18/07/19 16:11:03 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(0)
18/07/19 16:11:03 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 0: CPU
18/07/19 16:11:03 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId is 0, rg is CPU
18/07/19 16:11:03 INFO storage.memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 1448.0 B, free 727.2 MB)
18/07/19 16:11:03 INFO storage.memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 1006.0 B, free 727.2 MB)
18/07/19 16:11:03 INFO spark.storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.142.16.83:35848 (size: 1006.0 B, free: 727.2 MB)
18/07/19 16:11:03 INFO apache.spark.SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:997
18/07/19 16:11:03 INFO spark.scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (ParallelCollectionRDD[0] at parallelize at RequestGenerator.java:158)
18/07/19 16:11:03 INFO cluster.ego.EGODeployScheduler: Adding task set 0.0 with 2 tasks
18/07/19 16:11:03 INFO cluster.ego.EGOFineGrainedSchedulerBackend: <EVENT> Spark driver c7832b5d-e0a1-424d-8118-8278cff70d58 workload coming in
18/07/19 16:11:08 INFO cluster.ego.EGOFineGrainedSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (10.143.133.122:58418) with ID 2464f11d-a237-486a-8f00-1816e76a3453
18/07/19 16:11:08 INFO spark.storage.BlockManagerMasterEndpoint: Registering block manager yp-spark-dal09-env5-0030:40880 with 3.4 GB RAM, BlockManagerId(2464f11d-a237-486a-8f00-1816e76a3453, yp-spark-dal09-env5-0030, 40880, None)
18/07/19 16:11:08 WARN spark.scheduler.TaskSetManager: Stage 0 contains a task of very large size (205 KB). The maximum recommended task size is 100 KB.
18/07/19 16:11:08 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, yp-spark-dal09-env5-0030, executor 2464f11d-a237-486a-8f00-1816e76a3453, partition 0, PROCESS_LOCAL, 210363 bytes)
18/07/19 16:11:08 INFO cluster.ego.EGOFineGrainedSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (10.143.133.36:56720) with ID 3e315008-42c1-4ea7-956d-06cbeda3dad8
18/07/19 16:11:08 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 0 ( Index 0 ) on 2464f11d-a237-486a-8f00-1816e76a3453
18/07/19 16:11:08 INFO spark.storage.BlockManagerMasterEndpoint: Registering block manager yp-spark-dal09-env5-0044:33135 with 3.4 GB RAM, BlockManagerId(3e315008-42c1-4ea7-956d-06cbeda3dad8, yp-spark-dal09-env5-0044, 33135, None)
18/07/19 16:11:08 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, yp-spark-dal09-env5-0044, executor 3e315008-42c1-4ea7-956d-06cbeda3dad8, partition 1, PROCESS_LOCAL, 210363 bytes)
18/07/19 16:11:08 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 1 ( Index 1 ) on 3e315008-42c1-4ea7-956d-06cbeda3dad8
18/07/19 16:11:10 INFO spark.storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on yp-spark-dal09-env5-0030:40880 (size: 1006.0 B, free: 3.4 GB)
18/07/19 16:11:10 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2550 ms on yp-spark-dal09-env5-0030 (executor 2464f11d-a237-486a-8f00-1816e76a3453) (1/2)
18/07/19 16:11:10 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 0 ( Index 0 ) on 2464f11d-a237-486a-8f00-1816e76a3453 with SUCCESS
18/07/19 16:11:10 INFO spark.storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on yp-spark-dal09-env5-0044:33135 (size: 1006.0 B, free: 3.4 GB)
18/07/19 16:11:10 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2561 ms on yp-spark-dal09-env5-0044 (executor 3e315008-42c1-4ea7-956d-06cbeda3dad8) (2/2)
18/07/19 16:11:10 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 1 ( Index 1 ) on 3e315008-42c1-4ea7-956d-06cbeda3dad8 with SUCCESS
18/07/19 16:11:10 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/07/19 16:11:10 INFO spark.scheduler.DAGScheduler: ResultStage 0 (count at LoanValidationSparkRunner.java:267) finished in 7.557 s
18/07/19 16:11:10 INFO spark.scheduler.DAGScheduler: Job 0 finished: count at LoanValidationSparkRunner.java:267, took 7.709364 s
18/07/19 16:11:10 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(0)
18/07/19 16:11:10 INFO apache.spark.SparkContext: Starting job: count at LoanValidationSparkRunner.java:274
18/07/19 16:11:10 INFO spark.scheduler.DAGScheduler: Got job 1 (count at LoanValidationSparkRunner.java:274) with 2 output partitions
18/07/19 16:11:10 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 1 (count at LoanValidationSparkRunner.java:274)
18/07/19 16:11:10 INFO spark.scheduler.DAGScheduler: Parents of final stage: List()
18/07/19 16:11:10 INFO spark.scheduler.DAGScheduler: Missing parents: List()
18/07/19 16:11:10 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[1] at map at LoanValidationSparkRunner.java:273), which has no missing parents
18/07/19 16:11:10 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(1)
18/07/19 16:11:10 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 1: CPU
18/07/19 16:11:10 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 0: CPU
18/07/19 16:11:10 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId is 1, rg is CPU
18/07/19 16:11:10 INFO storage.memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 2.1 KB, free 727.2 MB)
18/07/19 16:11:10 INFO storage.memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 1383.0 B, free 727.2 MB)
18/07/19 16:11:10 INFO spark.storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.142.16.83:35848 (size: 1383.0 B, free: 727.2 MB)
18/07/19 16:11:10 INFO apache.spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:997
18/07/19 16:11:10 INFO spark.scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[1] at map at LoanValidationSparkRunner.java:273)
18/07/19 16:11:10 INFO cluster.ego.EGODeployScheduler: Adding task set 1.0 with 2 tasks
18/07/19 16:11:10 WARN spark.scheduler.TaskSetManager: Stage 1 contains a task of very large size (205 KB). The maximum recommended task size is 100 KB.
18/07/19 16:11:10 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, yp-spark-dal09-env5-0030, executor 2464f11d-a237-486a-8f00-1816e76a3453, partition 0, PROCESS_LOCAL, 210363 bytes)
18/07/19 16:11:10 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 2 ( Index 0 ) on 2464f11d-a237-486a-8f00-1816e76a3453
18/07/19 16:11:10 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, yp-spark-dal09-env5-0044, executor 3e315008-42c1-4ea7-956d-06cbeda3dad8, partition 1, PROCESS_LOCAL, 210363 bytes)
18/07/19 16:11:10 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 3 ( Index 1 ) on 3e315008-42c1-4ea7-956d-06cbeda3dad8
18/07/19 16:11:11 INFO spark.storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on yp-spark-dal09-env5-0030:40880 (size: 1383.0 B, free: 3.4 GB)
18/07/19 16:11:11 INFO spark.storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on yp-spark-dal09-env5-0044:33135 (size: 1383.0 B, free: 3.4 GB)
18/07/19 16:11:16 INFO spark.storage.BlockManagerInfo: Added rdd_1_1 in memory on yp-spark-dal09-env5-0044:33135 (size: 8.7 MB, free: 3.4 GB)
18/07/19 16:11:16 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 5587 ms on yp-spark-dal09-env5-0044 (executor 3e315008-42c1-4ea7-956d-06cbeda3dad8) (1/2)
18/07/19 16:11:16 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 3 ( Index 1 ) on 3e315008-42c1-4ea7-956d-06cbeda3dad8 with SUCCESS
18/07/19 16:11:16 INFO spark.storage.BlockManagerInfo: Added rdd_1_0 in memory on yp-spark-dal09-env5-0030:40880 (size: 8.7 MB, free: 3.4 GB)
18/07/19 16:11:16 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 5942 ms on yp-spark-dal09-env5-0030 (executor 2464f11d-a237-486a-8f00-1816e76a3453) (2/2)
18/07/19 16:11:16 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/07/19 16:11:16 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 2 ( Index 0 ) on 2464f11d-a237-486a-8f00-1816e76a3453 with SUCCESS
18/07/19 16:11:16 INFO spark.scheduler.DAGScheduler: ResultStage 1 (count at LoanValidationSparkRunner.java:274) finished in 5.943 s
18/07/19 16:11:16 INFO spark.scheduler.DAGScheduler: Job 1 finished: count at LoanValidationSparkRunner.java:274, took 5.968213 s
18/07/19 16:11:16 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(1)
18/07/19 16:11:16 INFO conf.Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
18/07/19 16:11:16 INFO conf.Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
18/07/19 16:11:16 INFO conf.Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
18/07/19 16:11:16 INFO conf.Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
18/07/19 16:11:16 INFO conf.Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
18/07/19 16:11:16 INFO lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/07/19 16:11:16 INFO spark.storage.BlockManagerInfo: Removed broadcast_1_piece0 on 10.142.16.83:35848 in memory (size: 1383.0 B, free: 727.2 MB)
18/07/19 16:11:16 INFO spark.storage.BlockManagerInfo: Removed broadcast_1_piece0 on yp-spark-dal09-env5-0044:33135 in memory (size: 1383.0 B, free: 3.4 GB)
18/07/19 16:11:16 INFO spark.storage.BlockManagerInfo: Removed broadcast_1_piece0 on yp-spark-dal09-env5-0030:40880 in memory (size: 1383.0 B, free: 3.4 GB)
18/07/19 16:11:17 INFO apache.spark.SparkContext: Starting job: saveAsTextFile at LoanValidationSparkRunner.java:300
18/07/19 16:11:17 INFO spark.scheduler.DAGScheduler: Got job 2 (saveAsTextFile at LoanValidationSparkRunner.java:300) with 1 output partitions
18/07/19 16:11:17 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 2 (saveAsTextFile at LoanValidationSparkRunner.java:300)
18/07/19 16:11:17 INFO spark.scheduler.DAGScheduler: Parents of final stage: List()
18/07/19 16:11:17 INFO spark.scheduler.DAGScheduler: Missing parents: List()
18/07/19 16:11:17 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[4] at saveAsTextFile at LoanValidationSparkRunner.java:300), which has no missing parents
18/07/19 16:11:17 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(2)
18/07/19 16:11:17 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 4: CPU
18/07/19 16:11:17 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 0: CPU
18/07/19 16:11:17 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 2: CPU
18/07/19 16:11:17 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 3: CPU
18/07/19 16:11:17 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 1: CPU
18/07/19 16:11:17 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId is 2, rg is CPU
18/07/19 16:11:17 INFO storage.memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 73.6 KB, free 727.1 MB)
18/07/19 16:11:17 INFO storage.memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 26.6 KB, free 727.1 MB)
18/07/19 16:11:17 INFO spark.storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.142.16.83:35848 (size: 26.6 KB, free: 727.2 MB)
18/07/19 16:11:17 INFO apache.spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:997
18/07/19 16:11:17 INFO spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[4] at saveAsTextFile at LoanValidationSparkRunner.java:300)
18/07/19 16:11:17 INFO cluster.ego.EGODeployScheduler: Adding task set 2.0 with 1 tasks
18/07/19 16:11:17 WARN spark.scheduler.TaskSetManager: Stage 2 contains a task of very large size (402 KB). The maximum recommended task size is 100 KB.
18/07/19 16:11:17 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, yp-spark-dal09-env5-0030, executor 2464f11d-a237-486a-8f00-1816e76a3453, partition 0, PROCESS_LOCAL, 411704 bytes)
18/07/19 16:11:17 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 4 ( Index 0 ) on 2464f11d-a237-486a-8f00-1816e76a3453
18/07/19 16:11:17 INFO spark.storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on yp-spark-dal09-env5-0030:40880 (size: 26.6 KB, free: 3.4 GB)
18/07/19 16:11:19 INFO spark.storage.BlockManagerInfo: Added rdd_2_0 in memory on yp-spark-dal09-env5-0030:40880 (size: 9.6 MB, free: 3.4 GB)
18/07/19 16:11:20 INFO spark.storage.BlockManagerInfo: Added rdd_2_1 in memory on yp-spark-dal09-env5-0030:40880 (size: 9.6 MB, free: 3.4 GB)
18/07/19 16:11:20 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 3616 ms on yp-spark-dal09-env5-0030 (executor 2464f11d-a237-486a-8f00-1816e76a3453) (1/1)
18/07/19 16:11:20 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/07/19 16:11:20 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 4 ( Index 0 ) on 2464f11d-a237-486a-8f00-1816e76a3453 with SUCCESS
18/07/19 16:11:20 INFO spark.scheduler.DAGScheduler: ResultStage 2 (saveAsTextFile at LoanValidationSparkRunner.java:300) finished in 3.618 s
18/07/19 16:11:20 INFO spark.scheduler.DAGScheduler: Job 2 finished: saveAsTextFile at LoanValidationSparkRunner.java:300, took 3.672394 s
18/07/19 16:11:20 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(2)
18/07/19 16:11:20 INFO apache.spark.SparkContext: Starting job: count at LoanValidationSparkRunner.java:305
18/07/19 16:11:20 INFO spark.scheduler.DAGScheduler: Got job 3 (count at LoanValidationSparkRunner.java:305) with 2 output partitions
18/07/19 16:11:20 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 3 (count at LoanValidationSparkRunner.java:305)
18/07/19 16:11:20 INFO spark.scheduler.DAGScheduler: Parents of final stage: List()
18/07/19 16:11:20 INFO spark.scheduler.DAGScheduler: Missing parents: List()
18/07/19 16:11:20 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[1] at map at LoanValidationSparkRunner.java:273), which has no missing parents
18/07/19 16:11:20 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(3)
18/07/19 16:11:20 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 1: CPU
18/07/19 16:11:20 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 0: CPU
18/07/19 16:11:20 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId is 3, rg is CPU
18/07/19 16:11:20 INFO storage.memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 2.1 KB, free 727.1 MB)
18/07/19 16:11:20 INFO storage.memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 1383.0 B, free 727.1 MB)
18/07/19 16:11:20 INFO spark.storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.142.16.83:35848 (size: 1383.0 B, free: 727.2 MB)
18/07/19 16:11:20 INFO spark.storage.BlockManagerInfo: Removed broadcast_2_piece0 on 10.142.16.83:35848 in memory (size: 26.6 KB, free: 727.2 MB)
18/07/19 16:11:20 INFO apache.spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:997
18/07/19 16:11:20 INFO spark.scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[1] at map at LoanValidationSparkRunner.java:273)
18/07/19 16:11:20 INFO cluster.ego.EGODeployScheduler: Adding task set 3.0 with 2 tasks
18/07/19 16:11:20 INFO spark.storage.BlockManagerInfo: Removed broadcast_2_piece0 on yp-spark-dal09-env5-0030:40880 in memory (size: 26.6 KB, free: 3.4 GB)
18/07/19 16:11:20 WARN spark.scheduler.TaskSetManager: Stage 3 contains a task of very large size (205 KB). The maximum recommended task size is 100 KB.
18/07/19 16:11:20 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 5, yp-spark-dal09-env5-0030, executor 2464f11d-a237-486a-8f00-1816e76a3453, partition 0, PROCESS_LOCAL, 210363 bytes)
18/07/19 16:11:20 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 5 ( Index 0 ) on 2464f11d-a237-486a-8f00-1816e76a3453
18/07/19 16:11:20 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 3.0 (TID 6, yp-spark-dal09-env5-0044, executor 3e315008-42c1-4ea7-956d-06cbeda3dad8, partition 1, PROCESS_LOCAL, 210363 bytes)
18/07/19 16:11:20 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 6 ( Index 1 ) on 3e315008-42c1-4ea7-956d-06cbeda3dad8
18/07/19 16:11:20 INFO spark.storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on yp-spark-dal09-env5-0030:40880 (size: 1383.0 B, free: 3.4 GB)
18/07/19 16:11:20 INFO spark.storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on yp-spark-dal09-env5-0044:33135 (size: 1383.0 B, free: 3.4 GB)
18/07/19 16:11:20 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 5) in 81 ms on yp-spark-dal09-env5-0030 (executor 2464f11d-a237-486a-8f00-1816e76a3453) (1/2)
18/07/19 16:11:20 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 5 ( Index 0 ) on 2464f11d-a237-486a-8f00-1816e76a3453 with SUCCESS
18/07/19 16:11:20 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 3.0 (TID 6) in 77 ms on yp-spark-dal09-env5-0044 (executor 3e315008-42c1-4ea7-956d-06cbeda3dad8) (2/2)
18/07/19 16:11:20 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/07/19 16:11:20 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 6 ( Index 1 ) on 3e315008-42c1-4ea7-956d-06cbeda3dad8 with SUCCESS
18/07/19 16:11:20 INFO spark.scheduler.DAGScheduler: ResultStage 3 (count at LoanValidationSparkRunner.java:305) finished in 0.088 s
18/07/19 16:11:20 INFO spark.scheduler.DAGScheduler: Job 3 finished: count at LoanValidationSparkRunner.java:305, took 0.102946 s
18/07/19 16:11:20 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(3)
18/07/19 16:11:20 INFO apache.spark.SparkContext: Starting job: count at LoanValidationSparkRunner.java:307
18/07/19 16:11:20 INFO spark.scheduler.DAGScheduler: Got job 4 (count at LoanValidationSparkRunner.java:307) with 2 output partitions
18/07/19 16:11:20 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 4 (count at LoanValidationSparkRunner.java:307)
18/07/19 16:11:20 INFO spark.scheduler.DAGScheduler: Parents of final stage: List()
18/07/19 16:11:20 INFO spark.scheduler.DAGScheduler: Missing parents: List()
18/07/19 16:11:20 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[1] at map at LoanValidationSparkRunner.java:273), which has no missing parents
18/07/19 16:11:20 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(4)
18/07/19 16:11:20 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 1: CPU
18/07/19 16:11:20 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 0: CPU
18/07/19 16:11:20 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId is 4, rg is CPU
18/07/19 16:11:20 INFO storage.memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 2.1 KB, free 727.2 MB)
18/07/19 16:11:20 INFO cluster.ego.EGOFineGrainedSchedulerBackend: Spark driver enters idle mode
18/07/19 16:11:20 INFO storage.memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 1383.0 B, free 727.2 MB)
18/07/19 16:11:20 INFO spark.storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.142.16.83:35848 (size: 1383.0 B, free: 727.2 MB)
18/07/19 16:11:20 INFO apache.spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:997
18/07/19 16:11:20 INFO spark.scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[1] at map at LoanValidationSparkRunner.java:273)
18/07/19 16:11:20 INFO cluster.ego.EGODeployScheduler: Adding task set 4.0 with 2 tasks
18/07/19 16:11:20 WARN spark.scheduler.TaskSetManager: Stage 4 contains a task of very large size (205 KB). The maximum recommended task size is 100 KB.
18/07/19 16:11:20 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 4.0 (TID 7, yp-spark-dal09-env5-0044, executor 3e315008-42c1-4ea7-956d-06cbeda3dad8, partition 1, PROCESS_LOCAL, 210363 bytes)
18/07/19 16:11:20 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 7 ( Index 1 ) on 3e315008-42c1-4ea7-956d-06cbeda3dad8
18/07/19 16:11:20 INFO spark.storage.BlockManagerInfo: Removed broadcast_3_piece0 on 10.142.16.83:35848 in memory (size: 1383.0 B, free: 727.2 MB)
18/07/19 16:11:20 INFO spark.storage.BlockManagerInfo: Removed broadcast_3_piece0 on yp-spark-dal09-env5-0030:40880 in memory (size: 1383.0 B, free: 3.4 GB)
18/07/19 16:11:20 INFO spark.storage.BlockManagerInfo: Removed broadcast_3_piece0 on yp-spark-dal09-env5-0044:33135 in memory (size: 1383.0 B, free: 3.4 GB)
18/07/19 16:11:20 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 8, yp-spark-dal09-env5-0030, executor 2464f11d-a237-486a-8f00-1816e76a3453, partition 0, PROCESS_LOCAL, 210363 bytes)
18/07/19 16:11:20 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 8 ( Index 0 ) on 2464f11d-a237-486a-8f00-1816e76a3453
18/07/19 16:11:20 INFO spark.storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on yp-spark-dal09-env5-0030:40880 (size: 1383.0 B, free: 3.4 GB)
18/07/19 16:11:20 INFO spark.storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on yp-spark-dal09-env5-0044:33135 (size: 1383.0 B, free: 3.4 GB)
18/07/19 16:11:20 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 4.0 (TID 7) in 80 ms on yp-spark-dal09-env5-0044 (executor 3e315008-42c1-4ea7-956d-06cbeda3dad8) (1/2)
18/07/19 16:11:20 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 8) in 70 ms on yp-spark-dal09-env5-0030 (executor 2464f11d-a237-486a-8f00-1816e76a3453) (2/2)
18/07/19 16:11:20 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 7 ( Index 1 ) on 3e315008-42c1-4ea7-956d-06cbeda3dad8 with SUCCESS
18/07/19 16:11:20 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/07/19 16:11:20 INFO spark.scheduler.DAGScheduler: ResultStage 4 (count at LoanValidationSparkRunner.java:307) finished in 0.082 s
18/07/19 16:11:20 INFO spark.scheduler.DAGScheduler: Job 4 finished: count at LoanValidationSparkRunner.java:307, took 0.092617 s
18/07/19 16:11:20 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 8 ( Index 0 ) on 2464f11d-a237-486a-8f00-1816e76a3453 with SUCCESS
18/07/19 16:11:20 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(4)
18/07/19 16:11:20 INFO apache.spark.SparkContext: Starting job: count at LoanValidationSparkRunner.java:312
18/07/19 16:11:20 INFO spark.scheduler.DAGScheduler: Got job 5 (count at LoanValidationSparkRunner.java:312) with 2 output partitions
18/07/19 16:11:20 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 5 (count at LoanValidationSparkRunner.java:312)
18/07/19 16:11:20 INFO spark.scheduler.DAGScheduler: Parents of final stage: List()
18/07/19 16:11:20 INFO spark.scheduler.DAGScheduler: Missing parents: List()
18/07/19 16:11:20 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[5] at filter at LoanValidationSparkRunner.java:312), which has no missing parents
18/07/19 16:11:20 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(5)
18/07/19 16:11:20 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 5: CPU
18/07/19 16:11:20 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 0: CPU
18/07/19 16:11:20 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 1: CPU
18/07/19 16:11:20 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId is 5, rg is CPU
18/07/19 16:11:20 INFO storage.memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 2.4 KB, free 727.2 MB)
18/07/19 16:11:20 INFO storage.memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 1494.0 B, free 727.2 MB)
18/07/19 16:11:20 INFO spark.storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.142.16.83:35848 (size: 1494.0 B, free: 727.2 MB)
18/07/19 16:11:20 INFO apache.spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:997
18/07/19 16:11:20 INFO spark.scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 5 (MapPartitionsRDD[5] at filter at LoanValidationSparkRunner.java:312)
18/07/19 16:11:20 INFO cluster.ego.EGODeployScheduler: Adding task set 5.0 with 2 tasks
18/07/19 16:11:20 WARN spark.scheduler.TaskSetManager: Stage 5 contains a task of very large size (205 KB). The maximum recommended task size is 100 KB.
18/07/19 16:11:20 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 9, yp-spark-dal09-env5-0030, executor 2464f11d-a237-486a-8f00-1816e76a3453, partition 0, PROCESS_LOCAL, 210363 bytes)
18/07/19 16:11:21 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 9 ( Index 0 ) on 2464f11d-a237-486a-8f00-1816e76a3453
18/07/19 16:11:21 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 5.0 (TID 10, yp-spark-dal09-env5-0044, executor 3e315008-42c1-4ea7-956d-06cbeda3dad8, partition 1, PROCESS_LOCAL, 210363 bytes)
18/07/19 16:11:21 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 10 ( Index 1 ) on 3e315008-42c1-4ea7-956d-06cbeda3dad8
18/07/19 16:11:21 INFO spark.storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on yp-spark-dal09-env5-0030:40880 (size: 1494.0 B, free: 3.4 GB)
18/07/19 16:11:21 INFO spark.storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on yp-spark-dal09-env5-0044:33135 (size: 1494.0 B, free: 3.4 GB)
18/07/19 16:11:21 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 5.0 (TID 10) in 73 ms on yp-spark-dal09-env5-0044 (executor 3e315008-42c1-4ea7-956d-06cbeda3dad8) (1/2)
18/07/19 16:11:21 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 9) in 84 ms on yp-spark-dal09-env5-0030 (executor 2464f11d-a237-486a-8f00-1816e76a3453) (2/2)
18/07/19 16:11:21 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/07/19 16:11:21 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 10 ( Index 1 ) on 3e315008-42c1-4ea7-956d-06cbeda3dad8 with SUCCESS
18/07/19 16:11:21 INFO spark.scheduler.DAGScheduler: ResultStage 5 (count at LoanValidationSparkRunner.java:312) finished in 0.085 s
18/07/19 16:11:21 INFO spark.scheduler.DAGScheduler: Job 5 finished: count at LoanValidationSparkRunner.java:312, took 0.099986 s
18/07/19 16:11:21 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 9 ( Index 0 ) on 2464f11d-a237-486a-8f00-1816e76a3453 with SUCCESS
18/07/19 16:11:21 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(5)
18/07/19 16:11:21 INFO apache.spark.SparkContext: Starting job: count at LoanValidationSparkRunner.java:316
18/07/19 16:11:21 INFO spark.scheduler.DAGScheduler: Got job 6 (count at LoanValidationSparkRunner.java:316) with 2 output partitions
18/07/19 16:11:21 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 6 (count at LoanValidationSparkRunner.java:316)
18/07/19 16:11:21 INFO spark.scheduler.DAGScheduler: Parents of final stage: List()
18/07/19 16:11:21 INFO spark.scheduler.DAGScheduler: Missing parents: List()
18/07/19 16:11:21 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[7] at filter at LoanValidationSparkRunner.java:316), which has no missing parents
18/07/19 16:11:21 INFO storage.memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.5 KB, free 727.2 MB)
18/07/19 16:11:21 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(6)
18/07/19 16:11:21 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 7: CPU
18/07/19 16:11:21 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 0: CPU
18/07/19 16:11:21 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 6: CPU
18/07/19 16:11:21 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 1: CPU
18/07/19 16:11:21 INFO storage.memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1527.0 B, free 727.2 MB)
18/07/19 16:11:21 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId is 6, rg is CPU
18/07/19 16:11:21 INFO spark.storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.142.16.83:35848 (size: 1527.0 B, free: 727.2 MB)
18/07/19 16:11:21 INFO spark.storage.BlockManagerInfo: Removed broadcast_5_piece0 on 10.142.16.83:35848 in memory (size: 1494.0 B, free: 727.2 MB)
18/07/19 16:11:21 INFO apache.spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:997
18/07/19 16:11:21 INFO spark.scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 6 (MapPartitionsRDD[7] at filter at LoanValidationSparkRunner.java:316)
18/07/19 16:11:21 INFO cluster.ego.EGODeployScheduler: Adding task set 6.0 with 2 tasks
18/07/19 16:11:21 INFO spark.storage.BlockManagerInfo: Removed broadcast_5_piece0 on yp-spark-dal09-env5-0044:33135 in memory (size: 1494.0 B, free: 3.4 GB)
18/07/19 16:11:21 INFO spark.storage.BlockManagerInfo: Removed broadcast_5_piece0 on yp-spark-dal09-env5-0030:40880 in memory (size: 1494.0 B, free: 3.4 GB)
18/07/19 16:11:21 WARN spark.scheduler.TaskSetManager: Stage 6 contains a task of very large size (205 KB). The maximum recommended task size is 100 KB.
18/07/19 16:11:21 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 6.0 (TID 11, yp-spark-dal09-env5-0044, executor 3e315008-42c1-4ea7-956d-06cbeda3dad8, partition 1, PROCESS_LOCAL, 210363 bytes)
18/07/19 16:11:21 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 11 ( Index 1 ) on 3e315008-42c1-4ea7-956d-06cbeda3dad8
18/07/19 16:11:21 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 12, yp-spark-dal09-env5-0030, executor 2464f11d-a237-486a-8f00-1816e76a3453, partition 0, PROCESS_LOCAL, 210363 bytes)
18/07/19 16:11:21 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 12 ( Index 0 ) on 2464f11d-a237-486a-8f00-1816e76a3453
18/07/19 16:11:21 INFO spark.storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on yp-spark-dal09-env5-0030:40880 (size: 1527.0 B, free: 3.4 GB)
18/07/19 16:11:21 INFO spark.storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on yp-spark-dal09-env5-0044:33135 (size: 1527.0 B, free: 3.4 GB)
18/07/19 16:11:21 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 12) in 66 ms on yp-spark-dal09-env5-0030 (executor 2464f11d-a237-486a-8f00-1816e76a3453) (1/2)
18/07/19 16:11:21 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 12 ( Index 0 ) on 2464f11d-a237-486a-8f00-1816e76a3453 with SUCCESS
18/07/19 16:11:21 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 6.0 (TID 11) in 83 ms on yp-spark-dal09-env5-0044 (executor 3e315008-42c1-4ea7-956d-06cbeda3dad8) (2/2)
18/07/19 16:11:21 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool 
18/07/19 16:11:21 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 11 ( Index 1 ) on 3e315008-42c1-4ea7-956d-06cbeda3dad8 with SUCCESS
18/07/19 16:11:21 INFO spark.scheduler.DAGScheduler: ResultStage 6 (count at LoanValidationSparkRunner.java:316) finished in 0.084 s
18/07/19 16:11:21 INFO spark.scheduler.DAGScheduler: Job 6 finished: count at LoanValidationSparkRunner.java:316, took 0.098746 s
18/07/19 16:11:21 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(6)
18/07/19 16:11:21 INFO apache.spark.SparkContext: Starting job: count at LoanValidationSparkRunner.java:319
18/07/19 16:11:21 INFO spark.scheduler.DAGScheduler: Got job 7 (count at LoanValidationSparkRunner.java:319) with 2 output partitions
18/07/19 16:11:21 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 7 (count at LoanValidationSparkRunner.java:319)
18/07/19 16:11:21 INFO spark.scheduler.DAGScheduler: Parents of final stage: List()
18/07/19 16:11:21 INFO spark.scheduler.DAGScheduler: Missing parents: List()
18/07/19 16:11:21 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[1] at map at LoanValidationSparkRunner.java:273), which has no missing parents
18/07/19 16:11:21 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(7)
18/07/19 16:11:21 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 1: CPU
18/07/19 16:11:21 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 0: CPU
18/07/19 16:11:21 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId is 7, rg is CPU
18/07/19 16:11:21 INFO storage.memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 2.1 KB, free 727.2 MB)
18/07/19 16:11:21 INFO storage.memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 1383.0 B, free 727.2 MB)
18/07/19 16:11:21 INFO spark.storage.BlockManagerInfo: Removed broadcast_6_piece0 on 10.142.16.83:35848 in memory (size: 1527.0 B, free: 727.2 MB)
18/07/19 16:11:21 INFO spark.storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.142.16.83:35848 (size: 1383.0 B, free: 727.2 MB)
18/07/19 16:11:21 INFO apache.spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:997
18/07/19 16:11:21 INFO spark.scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[1] at map at LoanValidationSparkRunner.java:273)
18/07/19 16:11:21 INFO cluster.ego.EGODeployScheduler: Adding task set 7.0 with 2 tasks
18/07/19 16:11:21 INFO spark.storage.BlockManagerInfo: Removed broadcast_6_piece0 on yp-spark-dal09-env5-0044:33135 in memory (size: 1527.0 B, free: 3.4 GB)
18/07/19 16:11:21 INFO spark.storage.BlockManagerInfo: Removed broadcast_6_piece0 on yp-spark-dal09-env5-0030:40880 in memory (size: 1527.0 B, free: 3.4 GB)
18/07/19 16:11:21 WARN spark.scheduler.TaskSetManager: Stage 7 contains a task of very large size (205 KB). The maximum recommended task size is 100 KB.
18/07/19 16:11:21 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 7.0 (TID 13, yp-spark-dal09-env5-0044, executor 3e315008-42c1-4ea7-956d-06cbeda3dad8, partition 1, PROCESS_LOCAL, 210363 bytes)
18/07/19 16:11:21 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 13 ( Index 1 ) on 3e315008-42c1-4ea7-956d-06cbeda3dad8
18/07/19 16:11:21 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 7.0 (TID 14, yp-spark-dal09-env5-0030, executor 2464f11d-a237-486a-8f00-1816e76a3453, partition 0, PROCESS_LOCAL, 210363 bytes)
18/07/19 16:11:21 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 14 ( Index 0 ) on 2464f11d-a237-486a-8f00-1816e76a3453
18/07/19 16:11:21 INFO spark.storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on yp-spark-dal09-env5-0044:33135 (size: 1383.0 B, free: 3.4 GB)
18/07/19 16:11:21 INFO spark.storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on yp-spark-dal09-env5-0030:40880 (size: 1383.0 B, free: 3.4 GB)
18/07/19 16:11:21 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 7.0 (TID 13) in 71 ms on yp-spark-dal09-env5-0044 (executor 3e315008-42c1-4ea7-956d-06cbeda3dad8) (1/2)
18/07/19 16:11:21 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 13 ( Index 1 ) on 3e315008-42c1-4ea7-956d-06cbeda3dad8 with SUCCESS
18/07/19 16:11:21 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 7.0 (TID 14) in 69 ms on yp-spark-dal09-env5-0030 (executor 2464f11d-a237-486a-8f00-1816e76a3453) (2/2)
18/07/19 16:11:21 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool 
18/07/19 16:11:21 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 14 ( Index 0 ) on 2464f11d-a237-486a-8f00-1816e76a3453 with SUCCESS
18/07/19 16:11:21 INFO spark.scheduler.DAGScheduler: ResultStage 7 (count at LoanValidationSparkRunner.java:319) finished in 0.076 s
18/07/19 16:11:21 INFO spark.scheduler.DAGScheduler: Job 7 finished: count at LoanValidationSparkRunner.java:319, took 0.091599 s
18/07/19 16:11:21 INFO deploy.ego.EGOClusterDriverWrapper: Final app status: 0, exitCode: 0
18/07/19 16:11:21 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(7)
18/07/19 16:11:21 INFO deploy.ego.EGOClusterDriverWrapper: Sending driver program state to master
18/07/19 16:11:21 INFO apache.spark.SparkContext: Invoking stop() from shutdown hook
18/07/19 16:11:21 INFO cluster.ego.EGOFineGrainedSchedulerBackend: hosts Set(yp-spark-dal09-env5-0030, yp-spark-dal09-env5-0044) need to delete the cache data for application[%s] app-20180719161102-0067-dc6822d0-75cf-48c1-bfbd-4f99665edb12
18/07/19 16:11:21 INFO jetty.server.ServerConnector: Stopped Spark@915b49f2{HTTP/1.1}{0.0.0.0:0}
18/07/19 16:11:21 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-5ef33774{/stages/stage/kill,null,UNAVAILABLE,@Spark}
18/07/19 16:11:21 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-5dded2d1{/jobs/job/kill,null,UNAVAILABLE,@Spark}
18/07/19 16:11:21 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-38256129{/api,null,UNAVAILABLE,@Spark}
18/07/19 16:11:21 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-2a73fc09{/,null,UNAVAILABLE,@Spark}
18/07/19 16:11:21 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-3579e917{/static,null,UNAVAILABLE,@Spark}
18/07/19 16:11:21 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@36cf6ca7{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
18/07/19 16:11:21 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@4b882e56{/executors/threadDump,null,UNAVAILABLE,@Spark}
18/07/19 16:11:21 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-1c73e1f8{/executors/json,null,UNAVAILABLE,@Spark}
18/07/19 16:11:21 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-f0fb976{/executors,null,UNAVAILABLE,@Spark}
18/07/19 16:11:21 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-12c030a9{/environment/json,null,UNAVAILABLE,@Spark}
18/07/19 16:11:21 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-393d7a34{/environment,null,UNAVAILABLE,@Spark}
18/07/19 16:11:21 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-4c11a7fb{/storage/rdd/json,null,UNAVAILABLE,@Spark}
18/07/19 16:11:21 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@7e22f118{/storage/rdd,null,UNAVAILABLE,@Spark}
18/07/19 16:11:21 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@3ca24877{/storage/json,null,UNAVAILABLE,@Spark}
18/07/19 16:11:21 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-6e0b3f61{/storage,null,UNAVAILABLE,@Spark}
18/07/19 16:11:21 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@63ed6043{/stages/pool/json,null,UNAVAILABLE,@Spark}
18/07/19 16:11:21 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@7c5ab9df{/stages/pool,null,UNAVAILABLE,@Spark}
18/07/19 16:11:21 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@204628a0{/stages/stage/json,null,UNAVAILABLE,@Spark}
18/07/19 16:11:21 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-27721e2{/stages/stage,null,UNAVAILABLE,@Spark}
18/07/19 16:11:21 INFO network.client.TransportClientFactory: Successfully created connection to yp-spark-dal09-env5-0030/10.143.133.122:7342 after 70 ms (68 ms spent in bootstraps)
18/07/19 16:11:21 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-307f0b1{/stages/json,null,UNAVAILABLE,@Spark}
18/07/19 16:11:21 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@e96bfa5{/stages,null,UNAVAILABLE,@Spark}
18/07/19 16:11:21 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@579d23de{/jobs/job/json,null,UNAVAILABLE,@Spark}
18/07/19 16:11:21 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-459f43a8{/jobs/job,null,UNAVAILABLE,@Spark}
18/07/19 16:11:21 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-18e7378d{/jobs/json,null,UNAVAILABLE,@Spark}
18/07/19 16:11:21 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@48253b4f{/jobs,null,UNAVAILABLE,@Spark}
18/07/19 16:11:21 INFO spark.storage.BlockManagerInfo: Removed broadcast_7_piece0 on 10.142.16.83:35848 in memory (size: 1383.0 B, free: 727.2 MB)
18/07/19 16:11:21 INFO spark.storage.BlockManager: Removing RDD 2
18/07/19 16:11:21 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@5aa88675{/logout,null,UNAVAILABLE,@Spark}
18/07/19 16:11:21 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-2591aade{/login,null,UNAVAILABLE,@Spark}
18/07/19 16:11:21 INFO spark.storage.BlockManagerInfo: Removed broadcast_7_piece0 on yp-spark-dal09-env5-0030:40880 in memory (size: 1383.0 B, free: 3.4 GB)
18/07/19 16:11:21 INFO spark.storage.BlockManagerInfo: Removed broadcast_7_piece0 on yp-spark-dal09-env5-0044:33135 in memory (size: 1383.0 B, free: 3.4 GB)
18/07/19 16:11:21 INFO spark.ui.SparkUI: Stopped Spark web UI at http://10.142.16.83:42832
18/07/19 16:11:21 INFO network.client.TransportClientFactory: Successfully created connection to yp-spark-dal09-env5-0044/10.143.133.36:7342 after 18 ms (17 ms spent in bootstraps)
18/07/19 16:11:21 INFO cluster.ego.EGOFineGrainedSchedulerBackend: Waiting for rpc request receive the response.
18/07/19 16:11:21 WARN spark.storage.BlockManagerMaster: Failed to remove RDD 2 - Failed to create local dir in /tmp/spark-21-ego-master/work/blockmgr-02782553-91c5-4cae-a0c4-c7822395ebfd/17.
java.io.IOException: Failed to create local dir in /tmp/spark-21-ego-master/work/blockmgr-02782553-91c5-4cae-a0c4-c7822395ebfd/17.
	at org.apache.spark.storage.DiskBlockManager.getFile(DiskBlockManager.scala:89)
	at org.apache.spark.storage.DiskStore.remove(DiskStore.scala:111)
	at org.apache.spark.storage.BlockManager.removeBlockInternal(BlockManager.scala:1404)
	at org.apache.spark.storage.BlockManager.removeBlock(BlockManager.scala:1392)
	at org.apache.spark.storage.BlockManager$$anonfun$removeRdd$2.apply(BlockManager.scala:1366)
	at org.apache.spark.storage.BlockManager$$anonfun$removeRdd$2.apply(BlockManager.scala:1366)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.storage.BlockManager.removeRdd(BlockManager.scala:1366)
	at org.apache.spark.storage.BlockManagerSlaveEndpoint$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$2.apply$mcI$sp(BlockManagerSlaveEndpoint.scala:53)
	at org.apache.spark.storage.BlockManagerSlaveEndpoint$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$2.apply(BlockManagerSlaveEndpoint.scala:53)
	at org.apache.spark.storage.BlockManagerSlaveEndpoint$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$2.apply(BlockManagerSlaveEndpoint.scala:53)
	at org.apache.spark.storage.BlockManagerSlaveEndpoint$$anonfun$1.apply(BlockManagerSlaveEndpoint.scala:82)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1160)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:811)
18/07/19 16:11:21 ERROR apache.spark.ContextCleaner: Error cleaning RDD 2
org.apache.spark.SparkException: Exception thrown in awaitResult
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:77)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:75)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:125)
	at org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1712)
	at org.apache.spark.ContextCleaner.doCleanupRDD(ContextCleaner.scala:222)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$1.apply(ContextCleaner.scala:199)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$1.apply(ContextCleaner.scala:194)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1.apply$mcV$sp(ContextCleaner.scala:194)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1371)
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:187)
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:74)
Caused by: java.io.IOException: Failed to create local dir in /tmp/spark-21-ego-master/work/blockmgr-02782553-91c5-4cae-a0c4-c7822395ebfd/17.
	at org.apache.spark.storage.DiskBlockManager.getFile(DiskBlockManager.scala:89)
	at org.apache.spark.storage.DiskStore.remove(DiskStore.scala:111)
	at org.apache.spark.storage.BlockManager.removeBlockInternal(BlockManager.scala:1404)
	at org.apache.spark.storage.BlockManager.removeBlock(BlockManager.scala:1392)
	at org.apache.spark.storage.BlockManager$$anonfun$removeRdd$2.apply(BlockManager.scala:1366)
	at org.apache.spark.storage.BlockManager$$anonfun$removeRdd$2.apply(BlockManager.scala:1366)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.storage.BlockManager.removeRdd(BlockManager.scala:1366)
	at org.apache.spark.storage.BlockManagerSlaveEndpoint$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$2.apply$mcI$sp(BlockManagerSlaveEndpoint.scala:53)
	at org.apache.spark.storage.BlockManagerSlaveEndpoint$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$2.apply(BlockManagerSlaveEndpoint.scala:53)
	at org.apache.spark.storage.BlockManagerSlaveEndpoint$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$2.apply(BlockManagerSlaveEndpoint.scala:53)
	at org.apache.spark.storage.BlockManagerSlaveEndpoint$$anonfun$1.apply(BlockManagerSlaveEndpoint.scala:82)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1160)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:811)
18/07/19 16:11:21 INFO cluster.ego.EGODeployScheduler: Spark context stopped.
18/07/19 16:11:21 INFO apache.spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/07/19 16:11:21 INFO storage.memory.MemoryStore: MemoryStore cleared
18/07/19 16:11:21 INFO spark.storage.BlockManager: BlockManager stopped
18/07/19 16:11:21 INFO spark.storage.BlockManagerMaster: BlockManagerMaster stopped
18/07/19 16:11:21 INFO spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/07/19 16:11:21 INFO apache.spark.SparkContext: Successfully stopped SparkContext
18/07/19 16:11:21 INFO spark.util.ShutdownHookManager: Shutdown hook called
18/07/19 16:11:21 INFO spark.util.ShutdownHookManager: Deleting directory /tmp/spark-21-ego-master/work/spark-1892e956-8eaf-4dab-a4fe-404fb3e742fc
18/07/19 16:11:21 INFO deploy.ego.EGOClusterDriverWrapper: staging dir is None
18/07/19 16:11:21 INFO deploy.ego.EGOClusterDriverWrapper: Deleting local temp file /tmp/spark-21-ego-master/work/spark-driver-4c56a1d1-30c1-4bfc-8e99-e50cfc564fd0/simpleloanvalidationsparkrunner-1.0-SNAPSHOT-withodmrt.jar: true
18/07/19 16:11:21 INFO deploy.ego.EGOClusterDriverWrapper: Deleting local temp file /tmp/spark-21-ego-master/work/spark-driver-4c56a1d1-30c1-4bfc-8e99-e50cfc564fd0: true
