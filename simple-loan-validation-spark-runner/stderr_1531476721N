++++ /usr/local/src/analytic-libs/profile.sh 2.1 2.11 2.7
+++ local 'profiledata=EXTRA_CLASSPATH='\''/usr/local/src/analytic-libs/common/*:/usr/local/src/analytic-libs/spark-2.1/*'\'' EXTRA_PYTHONPATH='\''/usr/local/src/analytic-libs/spark-2.1/python-2.7:/usr/local/src/analytic-libs/spark-2.1/python:/usr/local/src/analytic-libs/python'\'''
+++ eval local 'EXTRA_CLASSPATH='\''/usr/local/src/analytic-libs/common/*:/usr/local/src/analytic-libs/spark-2.1/*'\''' 'EXTRA_PYTHONPATH='\''/usr/local/src/analytic-libs/spark-2.1/python-2.7:/usr/local/src/analytic-libs/spark-2.1/python:/usr/local/src/analytic-libs/python'\'''
++++ local 'EXTRA_CLASSPATH=/usr/local/src/analytic-libs/common/*:/usr/local/src/analytic-libs/spark-2.1/*' EXTRA_PYTHONPATH=/usr/local/src/analytic-libs/spark-2.1/python-2.7:/usr/local/src/analytic-libs/spark-2.1/python:/usr/local/src/analytic-libs/python
+++ [[ -n /usr/local/src/analytic-libs/common/*:/usr/local/src/analytic-libs/spark-2.1/* ]]
+++ export 'SPARK_DIST_CLASSPATH+=:/usr/local/src/analytic-libs/common/*:/usr/local/src/analytic-libs/spark-2.1/*'
+++ SPARK_DIST_CLASSPATH+=':/usr/local/src/analytic-libs/common/*:/usr/local/src/analytic-libs/spark-2.1/*'
+++ [[ -n /usr/local/src/analytic-libs/spark-2.1/python-2.7:/usr/local/src/analytic-libs/spark-2.1/python:/usr/local/src/analytic-libs/python ]]
+++ export PYTHONPATH+=:/usr/local/src/analytic-libs/spark-2.1/python-2.7:/usr/local/src/analytic-libs/spark-2.1/python:/usr/local/src/analytic-libs/python
+++ PYTHONPATH+=:/usr/local/src/analytic-libs/spark-2.1/python-2.7:/usr/local/src/analytic-libs/spark-2.1/python:/usr/local/src/analytic-libs/python
+++ [[ /usr/local/src/analytic-libs/profile.sh == */wml-libs* ]]
+++ set +x
++++ /usr/local/src/wml-libs/profile.sh 2.1 2.11 2.7
+++ local 'profiledata=EXTRA_CLASSPATH='\''/usr/local/src/wml-libs.v30/jars/*:/usr/local/src/wml-libs.v30/spark-2.1/jars/*:/usr/local/src/wml-libs.v30/spark-2.1/dataconnector-dw-2.1/*'\'' EXTRA_PYTHONPATH='\''/usr/local/src/wml-libs.v30/python-2.7:/usr/local/src/wml-libs.v30/spark-2.1/python-2.7'\'' TAM_DIR='\''/usr/local/src/wml-libs.v30/tam'\'''
+++ eval local 'EXTRA_CLASSPATH='\''/usr/local/src/wml-libs.v30/jars/*:/usr/local/src/wml-libs.v30/spark-2.1/jars/*:/usr/local/src/wml-libs.v30/spark-2.1/dataconnector-dw-2.1/*'\''' 'EXTRA_PYTHONPATH='\''/usr/local/src/wml-libs.v30/python-2.7:/usr/local/src/wml-libs.v30/spark-2.1/python-2.7'\''' 'TAM_DIR='\''/usr/local/src/wml-libs.v30/tam'\'''
++++ local 'EXTRA_CLASSPATH=/usr/local/src/wml-libs.v30/jars/*:/usr/local/src/wml-libs.v30/spark-2.1/jars/*:/usr/local/src/wml-libs.v30/spark-2.1/dataconnector-dw-2.1/*' EXTRA_PYTHONPATH=/usr/local/src/wml-libs.v30/python-2.7:/usr/local/src/wml-libs.v30/spark-2.1/python-2.7 TAM_DIR=/usr/local/src/wml-libs.v30/tam
+++ [[ -n /usr/local/src/wml-libs.v30/jars/*:/usr/local/src/wml-libs.v30/spark-2.1/jars/*:/usr/local/src/wml-libs.v30/spark-2.1/dataconnector-dw-2.1/* ]]
+++ export 'SPARK_DIST_CLASSPATH+=:/usr/local/src/wml-libs.v30/jars/*:/usr/local/src/wml-libs.v30/spark-2.1/jars/*:/usr/local/src/wml-libs.v30/spark-2.1/dataconnector-dw-2.1/*'
+++ SPARK_DIST_CLASSPATH+=':/usr/local/src/wml-libs.v30/jars/*:/usr/local/src/wml-libs.v30/spark-2.1/jars/*:/usr/local/src/wml-libs.v30/spark-2.1/dataconnector-dw-2.1/*'
+++ [[ -n /usr/local/src/wml-libs.v30/python-2.7:/usr/local/src/wml-libs.v30/spark-2.1/python-2.7 ]]
+++ export PYTHONPATH+=:/usr/local/src/wml-libs.v30/python-2.7:/usr/local/src/wml-libs.v30/spark-2.1/python-2.7
+++ PYTHONPATH+=:/usr/local/src/wml-libs.v30/python-2.7:/usr/local/src/wml-libs.v30/spark-2.1/python-2.7
+++ [[ /usr/local/src/wml-libs/profile.sh == */wml-libs* ]]
+++ [[ -n /usr/local/src/wml-libs.v30/tam ]]
+++ export NGWB_TAM_FILE_LOCATION=/usr/local/src/wml-libs.v30/tam
+++ NGWB_TAM_FILE_LOCATION=/usr/local/src/wml-libs.v30/tam
+++ set +x
Spark Command: /usr/local/src/spark21master/ibm-java-x86_64-80/bin/java -cp /usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/ego/spark-launcher_2.11-2.1.2.jar:/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/ego/spark-network-shuffle_2.11-2.1.2.jar:/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/ego/gson-2.2.4.jar:/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/ego/guava-14.0.1.jar:/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/ego/Java-WebSocket-1.3.0.jar:/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/ego/spark-ego_2.11-2.1.2.jar:/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/ego/spark-network-common_2.11-2.1.2.jar:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/thirdparty/avro-1.8.0.jar:/usr/local/src/spark21master/spark/profile/batch/:/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/jars/*:/usr/local/src/analytic-libs/common/*:/usr/local/src/analytic-libs/spark-2.1/*:/usr/local/src/wml-libs.v30/jars/*:/usr/local/src/wml-libs.v30/spark-2.1/jars/*:/usr/local/src/wml-libs.v30/spark-2.1/dataconnector-dw-2.1/*:/gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/data/libs/:/gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/data/libs/*:/gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/data/libs/scala-2.11:/gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/data/libs/scala-2.11/*:/usr/local/src/dataconnector-stocator/spark-2.0.0/libs/*:/usr/local/src/dataconnector-s3-2.0/spark-2.0.0/libs/*:/usr/local/src/dataconnector-cloudant-2.0/spark-2.0.0/libs/*:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/*:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jdbc/lib/*:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/thirdparty/*:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/libs/*:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/thirdparty/aws/*:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/config/:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/FaspStreamSDK/lib/*:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/jars/JISPlugins/*:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/branded_jdbc/lib/*:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/ASBServer/apps/lib/iis/*/*:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/connectors/*/*:/usr/local/src/event-stream-2.0/spark-2.0.0/libs/*:/usr/local/src/dataconnector-db2/*:/usr/local/src/datasource-idax/* -Dspark.executor.extraClassPath=/gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/data/libs/*: -Dspark.service.hashed_tenant_id=drqZ3lx0wZAjq+1tGx+RTTMzS35bUrX0bePBKA== -Dspark.eventLog.enabled=true -Dspark.master=spark://yp-spark-dal09-env5-0008:7089 -Dspark.service.plan_name=ibm.SparkService.PayGoPersonal -Dspark.authenticate.secret=.secret -Dspark.ego.authenticate.tenantSecret.pathPrefix=/gpfs/fs01/user -Dspark.service.spark_version=2.1 -Dspark.driver.extraLibraryPath=/gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/data/libs/*: -Dspark.authenticate.enableSaslEncryption=true -Dspark.eventLog.dir=/gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/events -Dspark.executor.extraLibraryPath=/gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/data/libs/*: -Dspark.driver.extraClassPath=/gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/data/libs/*: -Dspark.driver.extraJavaOptions=-Xdump:tool:events=excessivegc,exec=kill -9 %pid -Dspark.jars=/gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/data/dcd16e852f56c31cbdb9164738e2364f64296459/simpleloanvalidationsparkrunner-1.0-SNAPSHOT-withodmrt.jar -Dspark.executor.memory=1024m -Dspark.io.encryption.enabled=true -Dspark.ego.authenticate.tenantSecret.filename=.secret -Dspark.app.name=“loan-validation” -Dspark.network.sasl.serverAlwaysEncrypt=true -Dspark.driver.maxResultSize=1210M -Dspark.authenticate=true -Dspark.files.useFetchCache=false -Xdump:tool:events=excessivegc,exec=kill -9 %pid -Dspark.shuffle.service.port=7342 -Xmx1512m org.apache.spark.deploy.ego.EGOClusterDriverWrapper {{WORKER_URL}} /gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/data/dcd16e852f56c31cbdb9164738e2364f64296459/simpleloanvalidationsparkrunner-1.0-SNAPSHOT-withodmrt.jar com.ibm.decisions.spark.loanvalidation.LoanValidationSparkRunner --inputgen 1000 --output loanvalidation-decisions-1K.json
========================================
log4j:ERROR Could not find value for key log4j.appender.FILE
log4j:ERROR Could not instantiate appender named "FILE".
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/local/src/spark21master/spark-2.1.2-bin-2.7.3/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/src/wml-libs.v30/spark-2.0/jars/tika-app-2.0-1.14.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/src/wml-libs.v30/spark-2.0/jars/ml-event-client-scala-library-0.1.55-201709150512-allinone.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/src/dataconnector-dw-2.0/spark-2.0.0/Server/connectivity/thirdparty/slf4j-simple-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
18/07/13 05:15:31 INFO deploy.ego.EGOClusterDriverWrapper: Started daemon with process name: 12819@yp-spark-dal09-env5-0049
18/07/13 05:15:31 INFO spark.util.SignalUtils: Registered signal handler for TERM
18/07/13 05:15:31 INFO spark.util.SignalUtils: Registered signal handler for HUP
18/07/13 05:15:31 INFO spark.util.SignalUtils: Registered signal handler for INT
18/07/13 05:15:32 WARN hadoop.util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
18/07/13 05:15:32 INFO apache.spark.SecurityManager: Changing view acls to: sb1f-e2fb2aec88783d-178f40bd326e
18/07/13 05:15:32 INFO apache.spark.SecurityManager: Changing modify acls to: sb1f-e2fb2aec88783d-178f40bd326e
18/07/13 05:15:32 INFO apache.spark.SecurityManager: Changing view acls groups to: 
18/07/13 05:15:32 INFO apache.spark.SecurityManager: Changing modify acls groups to: 
18/07/13 05:15:32 INFO apache.spark.SecurityManager: SecurityManager: authentication enabled; ui acls disabled; users  with view permissions: Set(sb1f-e2fb2aec88783d-178f40bd326e); groups with view permissions: Set(); users  with modify permissions: Set(sb1f-e2fb2aec88783d-178f40bd326e); groups with modify permissions: Set()
18/07/13 05:15:32 INFO spark.util.Utils: Successfully started service 'EGOClusterDriverWrapper-driver-20180713051530-4958-eb7f0086-3008-4ae0-829c-caea57a96c76' on port 35705.
18/07/13 05:15:33 INFO network.client.TransportClientFactory: Successfully created connection to yp-spark-dal09-env5-0008/10.142.16.68:7089 after 657 ms (624 ms spent in bootstraps)
18/07/13 05:15:33 INFO apache.spark.SecurityManager: Changing view acls to: sb1f-e2fb2aec88783d-178f40bd326e
18/07/13 05:15:33 INFO apache.spark.SecurityManager: Changing modify acls to: sb1f-e2fb2aec88783d-178f40bd326e
18/07/13 05:15:33 INFO apache.spark.SecurityManager: Changing view acls groups to: 
18/07/13 05:15:33 INFO apache.spark.SecurityManager: Changing modify acls groups to: 
18/07/13 05:15:33 INFO apache.spark.SecurityManager: SecurityManager: authentication enabled; ui acls disabled; users  with view permissions: Set(sb1f-e2fb2aec88783d-178f40bd326e); groups with view permissions: Set(); users  with modify permissions: Set(sb1f-e2fb2aec88783d-178f40bd326e); groups with modify permissions: Set()
18/07/13 05:15:33 INFO deploy.ego.EGOClusterDriverWrapper: Fetching jar file from /gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/data/dcd16e852f56c31cbdb9164738e2364f64296459/simpleloanvalidationsparkrunner-1.0-SNAPSHOT-withodmrt.jar to /tmp/spark-21-ego-master/work/spark-driver-c2f2b275-5d12-4a36-b112-61dcb34a6935/simpleloanvalidationsparkrunner-1.0-SNAPSHOT-withodmrt.jar
18/07/13 05:15:33 INFO spark.util.Utils: Copying /gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/data/dcd16e852f56c31cbdb9164738e2364f64296459/simpleloanvalidationsparkrunner-1.0-SNAPSHOT-withodmrt.jar to /tmp/spark-21-ego-master/work/spark-driver-c2f2b275-5d12-4a36-b112-61dcb34a6935/simpleloanvalidationsparkrunner-1.0-SNAPSHOT-withodmrt.jar
18/07/13 05:15:33 INFO deploy.ego.EGOClusterDriverWrapper: Starting the user JAR in a separate Thread
18/07/13 05:15:33 INFO deploy.ego.EGOClusterDriverWrapper: Waiting for spark context initialization ... 0
18/07/13 05:15:33 INFO apache.spark.SparkContext: Running Spark version 2.1.2
18/07/13 05:15:34 INFO apache.spark.SecurityManager: Changing view acls to: sb1f-e2fb2aec88783d-178f40bd326e
18/07/13 05:15:34 INFO apache.spark.SecurityManager: Changing modify acls to: sb1f-e2fb2aec88783d-178f40bd326e
18/07/13 05:15:34 INFO apache.spark.SecurityManager: Changing view acls groups to: 
18/07/13 05:15:34 INFO apache.spark.SecurityManager: Changing modify acls groups to: 
18/07/13 05:15:34 INFO apache.spark.SecurityManager: SecurityManager: authentication enabled; ui acls disabled; users  with view permissions: Set(sb1f-e2fb2aec88783d-178f40bd326e); groups with view permissions: Set(); users  with modify permissions: Set(sb1f-e2fb2aec88783d-178f40bd326e); groups with modify permissions: Set()
18/07/13 05:15:34 INFO spark.util.Utils: Successfully started service 'sparkDriver' on port 32848.
18/07/13 05:15:34 INFO apache.spark.SparkEnv: Registering MapOutputTracker
18/07/13 05:15:34 INFO apache.spark.SparkEnv: Registering BlockManagerMaster
18/07/13 05:15:34 INFO spark.storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
18/07/13 05:15:34 INFO spark.storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
18/07/13 05:15:34 INFO storage.memory.MemoryStore: MemoryStore started with capacity 727.2 MB
18/07/13 05:15:34 INFO apache.spark.SparkEnv: Registering OutputCommitCoordinator
18/07/13 05:15:34 INFO jetty.util.log: Logging initialized @3341ms
18/07/13 05:15:34 INFO jetty.server.Server: jetty-9.2.z-SNAPSHOT
18/07/13 05:15:34 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-3b107387{/login,null,AVAILABLE,@Spark}
18/07/13 05:15:34 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1e38115a{/logout,null,AVAILABLE,@Spark}
18/07/13 05:15:34 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1d76e4d0{/jobs,null,AVAILABLE,@Spark}
18/07/13 05:15:34 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-33f791d6{/jobs/json,null,AVAILABLE,@Spark}
18/07/13 05:15:34 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-c8986d8{/jobs/job,null,AVAILABLE,@Spark}
18/07/13 05:15:34 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-65aebf12{/jobs/job/json,null,AVAILABLE,@Spark}
18/07/13 05:15:34 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-22ab775f{/stages,null,AVAILABLE,@Spark}
18/07/13 05:15:34 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5a0776f3{/stages/json,null,AVAILABLE,@Spark}
18/07/13 05:15:34 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-4c4c4e8{/stages/stage,null,AVAILABLE,@Spark}
18/07/13 05:15:34 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2de8facb{/stages/stage/json,null,AVAILABLE,@Spark}
18/07/13 05:15:34 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-35dd5b07{/stages/pool,null,AVAILABLE,@Spark}
18/07/13 05:15:34 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-4d8494af{/stages/pool/json,null,AVAILABLE,@Spark}
18/07/13 05:15:34 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@370cf89e{/storage,null,AVAILABLE,@Spark}
18/07/13 05:15:34 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-3a373355{/storage/json,null,AVAILABLE,@Spark}
18/07/13 05:15:34 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-369d15fc{/storage/rdd,null,AVAILABLE,@Spark}
18/07/13 05:15:34 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7f328d25{/storage/rdd/json,null,AVAILABLE,@Spark}
18/07/13 05:15:34 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-c42d6e2{/environment,null,AVAILABLE,@Spark}
18/07/13 05:15:34 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-69f44023{/environment/json,null,AVAILABLE,@Spark}
18/07/13 05:15:34 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@bccac1{/executors,null,AVAILABLE,@Spark}
18/07/13 05:15:34 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-9f05ecb{/executors/json,null,AVAILABLE,@Spark}
18/07/13 05:15:34 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-1f2eecfd{/executors/threadDump,null,AVAILABLE,@Spark}
18/07/13 05:15:34 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@d484891{/executors/threadDump/json,null,AVAILABLE,@Spark}
18/07/13 05:15:34 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-1135d78d{/static,null,AVAILABLE,@Spark}
18/07/13 05:15:34 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2cd5a6cb{/,null,AVAILABLE,@Spark}
18/07/13 05:15:34 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-19cbcc5d{/api,null,AVAILABLE,@Spark}
18/07/13 05:15:34 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@603b6f38{/jobs/job/kill,null,AVAILABLE,@Spark}
18/07/13 05:15:34 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@-5f967448{/stages/stage/kill,null,AVAILABLE,@Spark}
18/07/13 05:15:34 INFO jetty.server.ServerConnector: Started Spark@ee71b1a1{HTTP/1.1}{0.0.0.0:44787}
18/07/13 05:15:34 INFO jetty.server.Server: Started @3494ms
18/07/13 05:15:34 INFO spark.util.Utils: Successfully started service 'SparkUI' on port 44787.
18/07/13 05:15:34 INFO spark.ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://10.142.18.200:44787
18/07/13 05:15:34 INFO apache.spark.SparkContext: Added JAR /gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/data/dcd16e852f56c31cbdb9164738e2364f64296459/simpleloanvalidationsparkrunner-1.0-SNAPSHOT-withodmrt.jar at spark://10.142.18.200:32848/jars/simpleloanvalidationsparkrunner-1.0-SNAPSHOT-withodmrt.jar with timestamp 1531476934394
18/07/13 05:15:34 INFO spark.util.EGOSparkDockerConfig: Executor Container Type is 'normal' from local configuration file.
18/07/13 05:15:34 INFO spark.util.EGOSparkDockerConfig: Driver Container Type is 'normal' from local configuration file.
18/07/13 05:15:34 INFO spark.util.EGOSparkDockerConfig: spark-ego-docker.conf will not be parsed as docker is not defined as any container type.
18/07/13 05:15:34 INFO cluster.ego.EGOFineGrainedSchedulerBackend: setting reserve=0, priority=1, limit=2147483647, gpuLimit=2147483647, master=[Ljava.lang.String;@db9c217d
18/07/13 05:15:34 INFO client.ego.EGOAppClient$ClientEndpoint: Connecting to master spark://yp-spark-dal09-env5-0008:7089...
18/07/13 05:15:34 INFO network.client.TransportClientFactory: Successfully created connection to yp-spark-dal09-env5-0008/10.142.16.68:7089 after 54 ms (52 ms spent in bootstraps)
18/07/13 05:15:34 INFO network.client.TransportClientFactory: Successfully created connection to /10.142.18.200:35705 after 94 ms (93 ms spent in bootstraps)
18/07/13 05:15:34 INFO cluster.ego.EGOFineGrainedSchedulerBackend: Connected to Spark cluster with app ID app-20180713051534-4753-892fec60-09be-452f-a0f2-fe9a5f1a159e
18/07/13 05:15:34 INFO cluster.ego.EGOFineGrainedSchedulerBackend: Application registered successfully as app-20180713051534-4753-892fec60-09be-452f-a0f2-fe9a5f1a159e, executor Container type is normal
18/07/13 05:15:34 INFO spark.storage.DiskBlockManager: Init the driver local dir
18/07/13 05:15:34 INFO spark.storage.DiskBlockManager: Created local directory at /tmp/spark-21-ego-master/work/blockmgr-14340335-7aba-4375-8a14-fa5fa7178566
18/07/13 05:15:34 INFO spark.util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43424.
18/07/13 05:15:34 INFO network.netty.NettyBlockTransferService: Server created on 10.142.18.200:43424
18/07/13 05:15:34 INFO spark.storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
18/07/13 05:15:34 INFO spark.storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.142.18.200, 43424, None)
18/07/13 05:15:34 INFO spark.storage.BlockManagerMasterEndpoint: Registering block manager 10.142.18.200:43424 with 727.2 MB RAM, BlockManagerId(driver, 10.142.18.200, 43424, None)
18/07/13 05:15:34 INFO spark.storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.142.18.200, 43424, None)
18/07/13 05:15:34 INFO spark.storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.142.18.200, 43424, None)
18/07/13 05:15:34 INFO server.handler.ContextHandler: Started o.s.j.s.ServletContextHandler@703d7231{/metrics/json,null,AVAILABLE,@Spark}
18/07/13 05:15:34 INFO spark.scheduler.EventLoggingListener: Logging events to file:/gpfs/fs01/user/sb1f-e2fb2aec88783d-178f40bd326e/events/app-20180713051534-4753-892fec60-09be-452f-a0f2-fe9a5f1a159e
18/07/13 05:15:35 INFO cluster.ego.EGODeployScheduler: Spark context initialized.
18/07/13 05:15:35 INFO apache.spark.SparkContext: Starting job: count at LoanValidationSparkRunner.java:267
18/07/13 05:15:35 INFO spark.scheduler.DAGScheduler: Got job 0 (count at LoanValidationSparkRunner.java:267) with 2 output partitions
18/07/13 05:15:35 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 0 (count at LoanValidationSparkRunner.java:267)
18/07/13 05:15:35 INFO spark.scheduler.DAGScheduler: Parents of final stage: List()
18/07/13 05:15:35 INFO spark.scheduler.DAGScheduler: Missing parents: List()
18/07/13 05:15:35 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 0 (ParallelCollectionRDD[0] at parallelize at RequestGenerator.java:158), which has no missing parents
18/07/13 05:15:35 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(0)
18/07/13 05:15:35 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 0: CPU
18/07/13 05:15:35 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId is 0, rg is CPU
18/07/13 05:15:35 INFO storage.memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 1448.0 B, free 727.2 MB)
18/07/13 05:15:35 INFO storage.memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 1006.0 B, free 727.2 MB)
18/07/13 05:15:35 INFO spark.storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.142.18.200:43424 (size: 1006.0 B, free: 727.2 MB)
18/07/13 05:15:35 INFO apache.spark.SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:997
18/07/13 05:15:35 INFO spark.scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (ParallelCollectionRDD[0] at parallelize at RequestGenerator.java:158)
18/07/13 05:15:35 INFO cluster.ego.EGODeployScheduler: Adding task set 0.0 with 2 tasks
18/07/13 05:15:35 INFO cluster.ego.EGOFineGrainedSchedulerBackend: <EVENT> Spark driver 5afc920d-4411-4cc4-8a42-89e5e68ec6d5 workload coming in
18/07/13 05:15:41 INFO cluster.ego.EGOFineGrainedSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (10.142.18.202:56808) with ID d8dd77db-aa6d-4749-97cc-7043302d8a6e
18/07/13 05:15:41 INFO spark.storage.BlockManagerMasterEndpoint: Registering block manager yp-spark-dal09-env5-0034:40382 with 3.4 GB RAM, BlockManagerId(d8dd77db-aa6d-4749-97cc-7043302d8a6e, yp-spark-dal09-env5-0034, 40382, None)
18/07/13 05:15:41 WARN spark.scheduler.TaskSetManager: Stage 0 contains a task of very large size (205 KB). The maximum recommended task size is 100 KB.
18/07/13 05:15:41 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, yp-spark-dal09-env5-0034, executor d8dd77db-aa6d-4749-97cc-7043302d8a6e, partition 0, PROCESS_LOCAL, 210364 bytes)
18/07/13 05:15:41 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 0 ( Index 0 ) on d8dd77db-aa6d-4749-97cc-7043302d8a6e
18/07/13 05:15:41 INFO cluster.ego.EGOFineGrainedSchedulerBackend: Registered executor NettyRpcEndpointRef(null) (10.142.18.237:42804) with ID 0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239
18/07/13 05:15:41 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, yp-spark-dal09-env5-0035, executor 0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239, partition 1, PROCESS_LOCAL, 210364 bytes)
18/07/13 05:15:41 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 1 ( Index 1 ) on 0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239
18/07/13 05:15:41 INFO spark.storage.BlockManagerMasterEndpoint: Registering block manager yp-spark-dal09-env5-0035:39986 with 3.4 GB RAM, BlockManagerId(0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239, yp-spark-dal09-env5-0035, 39986, None)
18/07/13 05:15:43 INFO spark.storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on yp-spark-dal09-env5-0034:40382 (size: 1006.0 B, free: 3.4 GB)
18/07/13 05:15:43 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2633 ms on yp-spark-dal09-env5-0034 (executor d8dd77db-aa6d-4749-97cc-7043302d8a6e) (1/2)
18/07/13 05:15:43 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 0 ( Index 0 ) on d8dd77db-aa6d-4749-97cc-7043302d8a6e with SUCCESS
18/07/13 05:15:44 INFO spark.storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on yp-spark-dal09-env5-0035:39986 (size: 1006.0 B, free: 3.4 GB)
18/07/13 05:15:44 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 2768 ms on yp-spark-dal09-env5-0035 (executor 0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239) (2/2)
18/07/13 05:15:44 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 1 ( Index 1 ) on 0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239 with SUCCESS
18/07/13 05:15:44 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
18/07/13 05:15:44 INFO spark.scheduler.DAGScheduler: ResultStage 0 (count at LoanValidationSparkRunner.java:267) finished in 8.775 s
18/07/13 05:15:44 INFO spark.scheduler.DAGScheduler: Job 0 finished: count at LoanValidationSparkRunner.java:267, took 8.919581 s
18/07/13 05:15:44 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(0)
18/07/13 05:15:44 INFO apache.spark.SparkContext: Starting job: count at LoanValidationSparkRunner.java:274
18/07/13 05:15:44 INFO spark.scheduler.DAGScheduler: Got job 1 (count at LoanValidationSparkRunner.java:274) with 2 output partitions
18/07/13 05:15:44 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 1 (count at LoanValidationSparkRunner.java:274)
18/07/13 05:15:44 INFO spark.scheduler.DAGScheduler: Parents of final stage: List()
18/07/13 05:15:44 INFO spark.scheduler.DAGScheduler: Missing parents: List()
18/07/13 05:15:44 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[1] at map at LoanValidationSparkRunner.java:273), which has no missing parents
18/07/13 05:15:44 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(1)
18/07/13 05:15:44 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 1: CPU
18/07/13 05:15:44 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 0: CPU
18/07/13 05:15:44 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId is 1, rg is CPU
18/07/13 05:15:44 INFO storage.memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 2.1 KB, free 727.2 MB)
18/07/13 05:15:44 INFO storage.memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 1383.0 B, free 727.2 MB)
18/07/13 05:15:44 INFO spark.storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.142.18.200:43424 (size: 1383.0 B, free: 727.2 MB)
18/07/13 05:15:44 INFO apache.spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:997
18/07/13 05:15:44 INFO spark.scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[1] at map at LoanValidationSparkRunner.java:273)
18/07/13 05:15:44 INFO cluster.ego.EGODeployScheduler: Adding task set 1.0 with 2 tasks
18/07/13 05:15:44 WARN spark.scheduler.TaskSetManager: Stage 1 contains a task of very large size (205 KB). The maximum recommended task size is 100 KB.
18/07/13 05:15:44 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, yp-spark-dal09-env5-0034, executor d8dd77db-aa6d-4749-97cc-7043302d8a6e, partition 0, PROCESS_LOCAL, 210364 bytes)
18/07/13 05:15:44 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 2 ( Index 0 ) on d8dd77db-aa6d-4749-97cc-7043302d8a6e
18/07/13 05:15:44 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, yp-spark-dal09-env5-0035, executor 0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239, partition 1, PROCESS_LOCAL, 210364 bytes)
18/07/13 05:15:44 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 3 ( Index 1 ) on 0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239
18/07/13 05:15:44 INFO spark.storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on yp-spark-dal09-env5-0034:40382 (size: 1383.0 B, free: 3.4 GB)
18/07/13 05:15:44 INFO spark.storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on yp-spark-dal09-env5-0035:39986 (size: 1383.0 B, free: 3.4 GB)
18/07/13 05:15:49 INFO spark.storage.BlockManagerInfo: Added rdd_1_0 in memory on yp-spark-dal09-env5-0034:40382 (size: 8.7 MB, free: 3.4 GB)
18/07/13 05:15:49 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 5354 ms on yp-spark-dal09-env5-0034 (executor d8dd77db-aa6d-4749-97cc-7043302d8a6e) (1/2)
18/07/13 05:15:49 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 2 ( Index 0 ) on d8dd77db-aa6d-4749-97cc-7043302d8a6e with SUCCESS
18/07/13 05:15:50 INFO spark.storage.BlockManagerInfo: Added rdd_1_1 in memory on yp-spark-dal09-env5-0035:39986 (size: 8.7 MB, free: 3.4 GB)
18/07/13 05:15:50 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in 5886 ms on yp-spark-dal09-env5-0035 (executor 0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239) (2/2)
18/07/13 05:15:50 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool 
18/07/13 05:15:50 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 3 ( Index 1 ) on 0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239 with SUCCESS
18/07/13 05:15:50 INFO spark.scheduler.DAGScheduler: ResultStage 1 (count at LoanValidationSparkRunner.java:274) finished in 5.898 s
18/07/13 05:15:50 INFO spark.scheduler.DAGScheduler: Job 1 finished: count at LoanValidationSparkRunner.java:274, took 5.926782 s
18/07/13 05:15:50 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(1)
18/07/13 05:15:50 INFO conf.Configuration.deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
18/07/13 05:15:50 INFO conf.Configuration.deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
18/07/13 05:15:50 INFO conf.Configuration.deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
18/07/13 05:15:50 INFO conf.Configuration.deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
18/07/13 05:15:50 INFO conf.Configuration.deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
18/07/13 05:15:50 INFO lib.output.FileOutputCommitter: File Output Committer Algorithm version is 1
18/07/13 05:15:50 INFO apache.spark.SparkContext: Starting job: saveAsTextFile at LoanValidationSparkRunner.java:300
18/07/13 05:15:50 INFO spark.scheduler.DAGScheduler: Got job 2 (saveAsTextFile at LoanValidationSparkRunner.java:300) with 1 output partitions
18/07/13 05:15:50 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 2 (saveAsTextFile at LoanValidationSparkRunner.java:300)
18/07/13 05:15:50 INFO spark.scheduler.DAGScheduler: Parents of final stage: List()
18/07/13 05:15:50 INFO spark.scheduler.DAGScheduler: Missing parents: List()
18/07/13 05:15:50 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[4] at saveAsTextFile at LoanValidationSparkRunner.java:300), which has no missing parents
18/07/13 05:15:50 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(2)
18/07/13 05:15:50 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 4: CPU
18/07/13 05:15:50 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 0: CPU
18/07/13 05:15:50 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 3: CPU
18/07/13 05:15:50 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 1: CPU
18/07/13 05:15:50 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 2: CPU
18/07/13 05:15:50 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId is 2, rg is CPU
18/07/13 05:15:50 INFO storage.memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 73.6 KB, free 727.1 MB)
18/07/13 05:15:50 INFO storage.memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 26.6 KB, free 727.1 MB)
18/07/13 05:15:50 INFO spark.storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.142.18.200:43424 (size: 26.6 KB, free: 727.2 MB)
18/07/13 05:15:50 INFO apache.spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:997
18/07/13 05:15:50 INFO spark.scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[4] at saveAsTextFile at LoanValidationSparkRunner.java:300)
18/07/13 05:15:50 INFO cluster.ego.EGODeployScheduler: Adding task set 2.0 with 1 tasks
18/07/13 05:15:50 WARN spark.scheduler.TaskSetManager: Stage 2 contains a task of very large size (402 KB). The maximum recommended task size is 100 KB.
18/07/13 05:15:50 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, yp-spark-dal09-env5-0034, executor d8dd77db-aa6d-4749-97cc-7043302d8a6e, partition 0, PROCESS_LOCAL, 411705 bytes)
18/07/13 05:15:50 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 4 ( Index 0 ) on d8dd77db-aa6d-4749-97cc-7043302d8a6e
18/07/13 05:15:50 INFO spark.storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on yp-spark-dal09-env5-0034:40382 (size: 26.6 KB, free: 3.4 GB)
18/07/13 05:15:52 INFO spark.storage.BlockManagerInfo: Added rdd_2_0 in memory on yp-spark-dal09-env5-0034:40382 (size: 9.6 MB, free: 3.4 GB)
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Added rdd_2_1 in memory on yp-spark-dal09-env5-0034:40382 (size: 9.5 MB, free: 3.4 GB)
18/07/13 05:15:54 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 3705 ms on yp-spark-dal09-env5-0034 (executor d8dd77db-aa6d-4749-97cc-7043302d8a6e) (1/1)
18/07/13 05:15:54 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool 
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 4 ( Index 0 ) on d8dd77db-aa6d-4749-97cc-7043302d8a6e with SUCCESS
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: ResultStage 2 (saveAsTextFile at LoanValidationSparkRunner.java:300) finished in 3.707 s
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Job 2 finished: saveAsTextFile at LoanValidationSparkRunner.java:300, took 3.772148 s
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(2)
18/07/13 05:15:54 INFO apache.spark.SparkContext: Starting job: count at LoanValidationSparkRunner.java:305
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Got job 3 (count at LoanValidationSparkRunner.java:305) with 2 output partitions
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 3 (count at LoanValidationSparkRunner.java:305)
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Parents of final stage: List()
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Missing parents: List()
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[1] at map at LoanValidationSparkRunner.java:273), which has no missing parents
18/07/13 05:15:54 INFO storage.memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 2.1 KB, free 727.1 MB)
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(3)
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 1: CPU
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 0: CPU
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId is 3, rg is CPU
18/07/13 05:15:54 INFO storage.memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 1383.0 B, free 727.1 MB)
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.142.18.200:43424 (size: 1383.0 B, free: 727.2 MB)
18/07/13 05:15:54 INFO apache.spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:997
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[1] at map at LoanValidationSparkRunner.java:273)
18/07/13 05:15:54 INFO cluster.ego.EGODeployScheduler: Adding task set 3.0 with 2 tasks
18/07/13 05:15:54 WARN spark.scheduler.TaskSetManager: Stage 3 contains a task of very large size (205 KB). The maximum recommended task size is 100 KB.
18/07/13 05:15:54 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 5, yp-spark-dal09-env5-0034, executor d8dd77db-aa6d-4749-97cc-7043302d8a6e, partition 0, PROCESS_LOCAL, 210364 bytes)
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Removed broadcast_2_piece0 on 10.142.18.200:43424 in memory (size: 26.6 KB, free: 727.2 MB)
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 5 ( Index 0 ) on d8dd77db-aa6d-4749-97cc-7043302d8a6e
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Removed broadcast_2_piece0 on yp-spark-dal09-env5-0034:40382 in memory (size: 26.6 KB, free: 3.4 GB)
18/07/13 05:15:54 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 3.0 (TID 6, yp-spark-dal09-env5-0035, executor 0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239, partition 1, PROCESS_LOCAL, 210364 bytes)
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 6 ( Index 1 ) on 0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on yp-spark-dal09-env5-0034:40382 (size: 1383.0 B, free: 3.4 GB)
18/07/13 05:15:54 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 5) in 80 ms on yp-spark-dal09-env5-0034 (executor d8dd77db-aa6d-4749-97cc-7043302d8a6e) (1/2)
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 5 ( Index 0 ) on d8dd77db-aa6d-4749-97cc-7043302d8a6e with SUCCESS
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on yp-spark-dal09-env5-0035:39986 (size: 1383.0 B, free: 3.4 GB)
18/07/13 05:15:54 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 3.0 (TID 6) in 88 ms on yp-spark-dal09-env5-0035 (executor 0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239) (2/2)
18/07/13 05:15:54 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool 
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 6 ( Index 1 ) on 0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239 with SUCCESS
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: ResultStage 3 (count at LoanValidationSparkRunner.java:305) finished in 0.101 s
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Job 3 finished: count at LoanValidationSparkRunner.java:305, took 0.119028 s
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Removed broadcast_3_piece0 on 10.142.18.200:43424 in memory (size: 1383.0 B, free: 727.2 MB)
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(3)
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Removed broadcast_3_piece0 on yp-spark-dal09-env5-0034:40382 in memory (size: 1383.0 B, free: 3.4 GB)
18/07/13 05:15:54 INFO apache.spark.SparkContext: Starting job: count at LoanValidationSparkRunner.java:307
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Got job 4 (count at LoanValidationSparkRunner.java:307) with 2 output partitions
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 4 (count at LoanValidationSparkRunner.java:307)
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Parents of final stage: List()
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Missing parents: List()
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Removed broadcast_3_piece0 on yp-spark-dal09-env5-0035:39986 in memory (size: 1383.0 B, free: 3.4 GB)
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[1] at map at LoanValidationSparkRunner.java:273), which has no missing parents
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(4)
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 1: CPU
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 0: CPU
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId is 4, rg is CPU
18/07/13 05:15:54 INFO storage.memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 2.1 KB, free 727.2 MB)
18/07/13 05:15:54 INFO storage.memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 1383.0 B, free 727.2 MB)
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.142.18.200:43424 (size: 1383.0 B, free: 727.2 MB)
18/07/13 05:15:54 INFO apache.spark.SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:997
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[1] at map at LoanValidationSparkRunner.java:273)
18/07/13 05:15:54 INFO cluster.ego.EGODeployScheduler: Adding task set 4.0 with 2 tasks
18/07/13 05:15:54 WARN spark.scheduler.TaskSetManager: Stage 4 contains a task of very large size (205 KB). The maximum recommended task size is 100 KB.
18/07/13 05:15:54 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 7, yp-spark-dal09-env5-0034, executor d8dd77db-aa6d-4749-97cc-7043302d8a6e, partition 0, PROCESS_LOCAL, 210364 bytes)
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 7 ( Index 0 ) on d8dd77db-aa6d-4749-97cc-7043302d8a6e
18/07/13 05:15:54 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 4.0 (TID 8, yp-spark-dal09-env5-0035, executor 0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239, partition 1, PROCESS_LOCAL, 210364 bytes)
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 8 ( Index 1 ) on 0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on yp-spark-dal09-env5-0034:40382 (size: 1383.0 B, free: 3.4 GB)
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on yp-spark-dal09-env5-0035:39986 (size: 1383.0 B, free: 3.4 GB)
18/07/13 05:15:54 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 7) in 76 ms on yp-spark-dal09-env5-0034 (executor d8dd77db-aa6d-4749-97cc-7043302d8a6e) (1/2)
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 7 ( Index 0 ) on d8dd77db-aa6d-4749-97cc-7043302d8a6e with SUCCESS
18/07/13 05:15:54 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 4.0 (TID 8) in 74 ms on yp-spark-dal09-env5-0035 (executor 0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239) (2/2)
18/07/13 05:15:54 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool 
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 8 ( Index 1 ) on 0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239 with SUCCESS
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: ResultStage 4 (count at LoanValidationSparkRunner.java:307) finished in 0.083 s
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Job 4 finished: count at LoanValidationSparkRunner.java:307, took 0.102069 s
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Removed broadcast_4_piece0 on 10.142.18.200:43424 in memory (size: 1383.0 B, free: 727.2 MB)
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(4)
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Removed broadcast_4_piece0 on yp-spark-dal09-env5-0034:40382 in memory (size: 1383.0 B, free: 3.4 GB)
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Removed broadcast_4_piece0 on yp-spark-dal09-env5-0035:39986 in memory (size: 1383.0 B, free: 3.4 GB)
18/07/13 05:15:54 INFO apache.spark.SparkContext: Starting job: count at LoanValidationSparkRunner.java:312
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Got job 5 (count at LoanValidationSparkRunner.java:312) with 2 output partitions
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 5 (count at LoanValidationSparkRunner.java:312)
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Parents of final stage: List()
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Missing parents: List()
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[5] at filter at LoanValidationSparkRunner.java:312), which has no missing parents
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(5)
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 5: CPU
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 0: CPU
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 1: CPU
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId is 5, rg is CPU
18/07/13 05:15:54 INFO storage.memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 2.4 KB, free 727.2 MB)
18/07/13 05:15:54 INFO storage.memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 1494.0 B, free 727.2 MB)
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.142.18.200:43424 (size: 1494.0 B, free: 727.2 MB)
18/07/13 05:15:54 INFO apache.spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:997
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 5 (MapPartitionsRDD[5] at filter at LoanValidationSparkRunner.java:312)
18/07/13 05:15:54 INFO cluster.ego.EGODeployScheduler: Adding task set 5.0 with 2 tasks
18/07/13 05:15:54 WARN spark.scheduler.TaskSetManager: Stage 5 contains a task of very large size (205 KB). The maximum recommended task size is 100 KB.
18/07/13 05:15:54 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 5.0 (TID 9, yp-spark-dal09-env5-0035, executor 0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239, partition 1, PROCESS_LOCAL, 210364 bytes)
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 9 ( Index 1 ) on 0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239
18/07/13 05:15:54 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 10, yp-spark-dal09-env5-0034, executor d8dd77db-aa6d-4749-97cc-7043302d8a6e, partition 0, PROCESS_LOCAL, 210364 bytes)
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 10 ( Index 0 ) on d8dd77db-aa6d-4749-97cc-7043302d8a6e
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on yp-spark-dal09-env5-0034:40382 (size: 1494.0 B, free: 3.4 GB)
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on yp-spark-dal09-env5-0035:39986 (size: 1494.0 B, free: 3.4 GB)
18/07/13 05:15:54 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 10) in 63 ms on yp-spark-dal09-env5-0034 (executor d8dd77db-aa6d-4749-97cc-7043302d8a6e) (1/2)
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 10 ( Index 0 ) on d8dd77db-aa6d-4749-97cc-7043302d8a6e with SUCCESS
18/07/13 05:15:54 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 5.0 (TID 9) in 78 ms on yp-spark-dal09-env5-0035 (executor 0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239) (2/2)
18/07/13 05:15:54 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool 
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 9 ( Index 1 ) on 0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239 with SUCCESS
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: ResultStage 5 (count at LoanValidationSparkRunner.java:312) finished in 0.080 s
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Job 5 finished: count at LoanValidationSparkRunner.java:312, took 0.092913 s
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(5)
18/07/13 05:15:54 INFO apache.spark.SparkContext: Starting job: count at LoanValidationSparkRunner.java:316
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Got job 6 (count at LoanValidationSparkRunner.java:316) with 2 output partitions
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 6 (count at LoanValidationSparkRunner.java:316)
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Parents of final stage: List()
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Missing parents: List()
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[7] at filter at LoanValidationSparkRunner.java:316), which has no missing parents
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(6)
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 7: CPU
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 0: CPU
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 1: CPU
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 6: CPU
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId is 6, rg is CPU
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Removed broadcast_5_piece0 on 10.142.18.200:43424 in memory (size: 1494.0 B, free: 727.2 MB)
18/07/13 05:15:54 INFO storage.memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 2.5 KB, free 727.2 MB)
18/07/13 05:15:54 INFO storage.memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 1527.0 B, free 727.2 MB)
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.142.18.200:43424 (size: 1527.0 B, free: 727.2 MB)
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Removed broadcast_5_piece0 on yp-spark-dal09-env5-0035:39986 in memory (size: 1494.0 B, free: 3.4 GB)
18/07/13 05:15:54 INFO apache.spark.SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:997
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Removed broadcast_5_piece0 on yp-spark-dal09-env5-0034:40382 in memory (size: 1494.0 B, free: 3.4 GB)
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 6 (MapPartitionsRDD[7] at filter at LoanValidationSparkRunner.java:316)
18/07/13 05:15:54 INFO cluster.ego.EGODeployScheduler: Adding task set 6.0 with 2 tasks
18/07/13 05:15:54 WARN spark.scheduler.TaskSetManager: Stage 6 contains a task of very large size (205 KB). The maximum recommended task size is 100 KB.
18/07/13 05:15:54 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 11, yp-spark-dal09-env5-0034, executor d8dd77db-aa6d-4749-97cc-7043302d8a6e, partition 0, PROCESS_LOCAL, 210364 bytes)
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 11 ( Index 0 ) on d8dd77db-aa6d-4749-97cc-7043302d8a6e
18/07/13 05:15:54 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 6.0 (TID 12, yp-spark-dal09-env5-0035, executor 0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239, partition 1, PROCESS_LOCAL, 210364 bytes)
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 12 ( Index 1 ) on 0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on yp-spark-dal09-env5-0034:40382 (size: 1527.0 B, free: 3.4 GB)
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on yp-spark-dal09-env5-0035:39986 (size: 1527.0 B, free: 3.4 GB)
18/07/13 05:15:54 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 11) in 77 ms on yp-spark-dal09-env5-0034 (executor d8dd77db-aa6d-4749-97cc-7043302d8a6e) (1/2)
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 11 ( Index 0 ) on d8dd77db-aa6d-4749-97cc-7043302d8a6e with SUCCESS
18/07/13 05:15:54 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 6.0 (TID 12) in 76 ms on yp-spark-dal09-env5-0035 (executor 0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239) (2/2)
18/07/13 05:15:54 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool 
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 12 ( Index 1 ) on 0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239 with SUCCESS
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: ResultStage 6 (count at LoanValidationSparkRunner.java:316) finished in 0.088 s
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Job 6 finished: count at LoanValidationSparkRunner.java:316, took 0.106620 s
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(6)
18/07/13 05:15:54 INFO apache.spark.SparkContext: Starting job: count at LoanValidationSparkRunner.java:319
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Got job 7 (count at LoanValidationSparkRunner.java:319) with 2 output partitions
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Final stage: ResultStage 7 (count at LoanValidationSparkRunner.java:319)
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Parents of final stage: List()
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Missing parents: List()
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[1] at map at LoanValidationSparkRunner.java:273), which has no missing parents
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId(7)
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 1: CPU
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: RDD 0: CPU
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageSubmitted: stageId is 7, rg is CPU
18/07/13 05:15:54 INFO storage.memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 2.1 KB, free 727.2 MB)
18/07/13 05:15:54 INFO storage.memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 1383.0 B, free 727.2 MB)
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Removed broadcast_6_piece0 on 10.142.18.200:43424 in memory (size: 1527.0 B, free: 727.2 MB)
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.142.18.200:43424 (size: 1383.0 B, free: 727.2 MB)
18/07/13 05:15:54 INFO apache.spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:997
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[1] at map at LoanValidationSparkRunner.java:273)
18/07/13 05:15:54 INFO cluster.ego.EGODeployScheduler: Adding task set 7.0 with 2 tasks
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Removed broadcast_6_piece0 on yp-spark-dal09-env5-0034:40382 in memory (size: 1527.0 B, free: 3.4 GB)
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Removed broadcast_6_piece0 on yp-spark-dal09-env5-0035:39986 in memory (size: 1527.0 B, free: 3.4 GB)
18/07/13 05:15:54 WARN spark.scheduler.TaskSetManager: Stage 7 contains a task of very large size (205 KB). The maximum recommended task size is 100 KB.
18/07/13 05:15:54 INFO spark.scheduler.TaskSetManager: Starting task 1.0 in stage 7.0 (TID 13, yp-spark-dal09-env5-0035, executor 0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239, partition 1, PROCESS_LOCAL, 210364 bytes)
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 13 ( Index 1 ) on 0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239
18/07/13 05:15:54 INFO spark.scheduler.TaskSetManager: Starting task 0.0 in stage 7.0 (TID 14, yp-spark-dal09-env5-0034, executor d8dd77db-aa6d-4749-97cc-7043302d8a6e, partition 0, PROCESS_LOCAL, 210364 bytes)
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskStart: TID 14 ( Index 0 ) on d8dd77db-aa6d-4749-97cc-7043302d8a6e
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on yp-spark-dal09-env5-0035:39986 (size: 1383.0 B, free: 3.4 GB)
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on yp-spark-dal09-env5-0034:40382 (size: 1383.0 B, free: 3.4 GB)
18/07/13 05:15:54 INFO spark.scheduler.TaskSetManager: Finished task 1.0 in stage 7.0 (TID 13) in 71 ms on yp-spark-dal09-env5-0035 (executor 0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239) (1/2)
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 13 ( Index 1 ) on 0fdb36f5-b5d4-4e91-b4cd-d953c7ff7239 with SUCCESS
18/07/13 05:15:54 INFO spark.scheduler.TaskSetManager: Finished task 0.0 in stage 7.0 (TID 14) in 66 ms on yp-spark-dal09-env5-0034 (executor d8dd77db-aa6d-4749-97cc-7043302d8a6e) (2/2)
18/07/13 05:15:54 INFO cluster.ego.EGODeployScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool 
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: ResultStage 7 (count at LoanValidationSparkRunner.java:319) finished in 0.073 s
18/07/13 05:15:54 INFO spark.scheduler.DAGScheduler: Job 7 finished: count at LoanValidationSparkRunner.java:319, took 0.090132 s
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onTaskEnd: TID 14 ( Index 0 ) on d8dd77db-aa6d-4749-97cc-7043302d8a6e with SUCCESS
18/07/13 05:15:54 INFO deploy.ego.EGOClusterDriverWrapper: Final app status: 0, exitCode: 0
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: onStageCompleted: stageId(7)
18/07/13 05:15:54 INFO deploy.ego.EGOClusterDriverWrapper: Sending driver program state to master
18/07/13 05:15:54 INFO apache.spark.SparkContext: Invoking stop() from shutdown hook
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: hosts Set(yp-spark-dal09-env5-0034, yp-spark-dal09-env5-0035) need to delete the cache data for application[%s] app-20180713051534-4753-892fec60-09be-452f-a0f2-fe9a5f1a159e
18/07/13 05:15:54 INFO jetty.server.ServerConnector: Stopped Spark@ee71b1a1{HTTP/1.1}{0.0.0.0:0}
18/07/13 05:15:54 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-5f967448{/stages/stage/kill,null,UNAVAILABLE,@Spark}
18/07/13 05:15:54 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@603b6f38{/jobs/job/kill,null,UNAVAILABLE,@Spark}
18/07/13 05:15:54 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-19cbcc5d{/api,null,UNAVAILABLE,@Spark}
18/07/13 05:15:54 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@2cd5a6cb{/,null,UNAVAILABLE,@Spark}
18/07/13 05:15:54 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-1135d78d{/static,null,UNAVAILABLE,@Spark}
18/07/13 05:15:54 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@d484891{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
18/07/13 05:15:54 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-1f2eecfd{/executors/threadDump,null,UNAVAILABLE,@Spark}
18/07/13 05:15:54 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-9f05ecb{/executors/json,null,UNAVAILABLE,@Spark}
18/07/13 05:15:54 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@bccac1{/executors,null,UNAVAILABLE,@Spark}
18/07/13 05:15:54 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-69f44023{/environment/json,null,UNAVAILABLE,@Spark}
18/07/13 05:15:54 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-c42d6e2{/environment,null,UNAVAILABLE,@Spark}
18/07/13 05:15:54 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@7f328d25{/storage/rdd/json,null,UNAVAILABLE,@Spark}
18/07/13 05:15:54 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-369d15fc{/storage/rdd,null,UNAVAILABLE,@Spark}
18/07/13 05:15:54 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-3a373355{/storage/json,null,UNAVAILABLE,@Spark}
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Removed broadcast_7_piece0 on 10.142.18.200:43424 in memory (size: 1383.0 B, free: 727.2 MB)
18/07/13 05:15:54 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@370cf89e{/storage,null,UNAVAILABLE,@Spark}
18/07/13 05:15:54 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-4d8494af{/stages/pool/json,null,UNAVAILABLE,@Spark}
18/07/13 05:15:54 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-35dd5b07{/stages/pool,null,UNAVAILABLE,@Spark}
18/07/13 05:15:54 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@2de8facb{/stages/stage/json,null,UNAVAILABLE,@Spark}
18/07/13 05:15:54 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-4c4c4e8{/stages/stage,null,UNAVAILABLE,@Spark}
18/07/13 05:15:54 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@5a0776f3{/stages/json,null,UNAVAILABLE,@Spark}
18/07/13 05:15:54 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-22ab775f{/stages,null,UNAVAILABLE,@Spark}
18/07/13 05:15:54 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-65aebf12{/jobs/job/json,null,UNAVAILABLE,@Spark}
18/07/13 05:15:54 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-c8986d8{/jobs/job,null,UNAVAILABLE,@Spark}
18/07/13 05:15:54 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-33f791d6{/jobs/json,null,UNAVAILABLE,@Spark}
18/07/13 05:15:54 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@1d76e4d0{/jobs,null,UNAVAILABLE,@Spark}
18/07/13 05:15:54 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@1e38115a{/logout,null,UNAVAILABLE,@Spark}
18/07/13 05:15:54 INFO network.client.TransportClientFactory: Successfully created connection to yp-spark-dal09-env5-0034/10.142.18.202:7342 after 104 ms (102 ms spent in bootstraps)
18/07/13 05:15:54 INFO server.handler.ContextHandler: Stopped o.s.j.s.ServletContextHandler@-3b107387{/login,null,UNAVAILABLE,@Spark}
18/07/13 05:15:54 INFO spark.storage.BlockManager: Removing RDD 2
18/07/13 05:15:54 INFO spark.ui.SparkUI: Stopped Spark web UI at http://10.142.18.200:44787
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Removed broadcast_7_piece0 on yp-spark-dal09-env5-0034:40382 in memory (size: 1383.0 B, free: 3.4 GB)
18/07/13 05:15:54 INFO spark.storage.BlockManagerInfo: Removed broadcast_7_piece0 on yp-spark-dal09-env5-0035:39986 in memory (size: 1383.0 B, free: 3.4 GB)
18/07/13 05:15:54 INFO network.client.TransportClientFactory: Successfully created connection to yp-spark-dal09-env5-0035/10.142.18.237:7342 after 17 ms (16 ms spent in bootstraps)
18/07/13 05:15:54 INFO cluster.ego.EGOFineGrainedSchedulerBackend: Waiting for rpc request receive the response.
18/07/13 05:15:54 WARN spark.storage.BlockManagerMaster: Failed to remove RDD 2 - Failed to create local dir in /tmp/spark-21-ego-master/work/blockmgr-026aec69-7490-439f-856e-097a58362078/17.
java.io.IOException: Failed to create local dir in /tmp/spark-21-ego-master/work/blockmgr-026aec69-7490-439f-856e-097a58362078/17.
	at org.apache.spark.storage.DiskBlockManager.getFile(DiskBlockManager.scala:89)
	at org.apache.spark.storage.DiskStore.remove(DiskStore.scala:111)
	at org.apache.spark.storage.BlockManager.removeBlockInternal(BlockManager.scala:1404)
	at org.apache.spark.storage.BlockManager.removeBlock(BlockManager.scala:1392)
	at org.apache.spark.storage.BlockManager$$anonfun$removeRdd$2.apply(BlockManager.scala:1366)
	at org.apache.spark.storage.BlockManager$$anonfun$removeRdd$2.apply(BlockManager.scala:1366)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.storage.BlockManager.removeRdd(BlockManager.scala:1366)
	at org.apache.spark.storage.BlockManagerSlaveEndpoint$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$2.apply$mcI$sp(BlockManagerSlaveEndpoint.scala:53)
	at org.apache.spark.storage.BlockManagerSlaveEndpoint$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$2.apply(BlockManagerSlaveEndpoint.scala:53)
	at org.apache.spark.storage.BlockManagerSlaveEndpoint$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$2.apply(BlockManagerSlaveEndpoint.scala:53)
	at org.apache.spark.storage.BlockManagerSlaveEndpoint$$anonfun$1.apply(BlockManagerSlaveEndpoint.scala:82)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1160)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:811)
18/07/13 05:15:54 ERROR apache.spark.ContextCleaner: Error cleaning RDD 2
org.apache.spark.SparkException: Exception thrown in awaitResult
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:77)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:75)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.storage.BlockManagerMaster.removeRdd(BlockManagerMaster.scala:125)
	at org.apache.spark.SparkContext.unpersistRDD(SparkContext.scala:1712)
	at org.apache.spark.ContextCleaner.doCleanupRDD(ContextCleaner.scala:222)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$1.apply(ContextCleaner.scala:199)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1$$anonfun$apply$mcV$sp$1.apply(ContextCleaner.scala:194)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.ContextCleaner$$anonfun$org$apache$spark$ContextCleaner$$keepCleaning$1.apply$mcV$sp(ContextCleaner.scala:194)
	at org.apache.spark.util.Utils$.tryOrStopSparkContext(Utils.scala:1371)
	at org.apache.spark.ContextCleaner.org$apache$spark$ContextCleaner$$keepCleaning(ContextCleaner.scala:187)
	at org.apache.spark.ContextCleaner$$anon$1.run(ContextCleaner.scala:74)
Caused by: java.io.IOException: Failed to create local dir in /tmp/spark-21-ego-master/work/blockmgr-026aec69-7490-439f-856e-097a58362078/17.
	at org.apache.spark.storage.DiskBlockManager.getFile(DiskBlockManager.scala:89)
	at org.apache.spark.storage.DiskStore.remove(DiskStore.scala:111)
	at org.apache.spark.storage.BlockManager.removeBlockInternal(BlockManager.scala:1404)
	at org.apache.spark.storage.BlockManager.removeBlock(BlockManager.scala:1392)
	at org.apache.spark.storage.BlockManager$$anonfun$removeRdd$2.apply(BlockManager.scala:1366)
	at org.apache.spark.storage.BlockManager$$anonfun$removeRdd$2.apply(BlockManager.scala:1366)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336)
	at org.apache.spark.storage.BlockManager.removeRdd(BlockManager.scala:1366)
	at org.apache.spark.storage.BlockManagerSlaveEndpoint$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$2.apply$mcI$sp(BlockManagerSlaveEndpoint.scala:53)
	at org.apache.spark.storage.BlockManagerSlaveEndpoint$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$2.apply(BlockManagerSlaveEndpoint.scala:53)
	at org.apache.spark.storage.BlockManagerSlaveEndpoint$$anonfun$receiveAndReply$1$$anonfun$applyOrElse$2.apply(BlockManagerSlaveEndpoint.scala:53)
	at org.apache.spark.storage.BlockManagerSlaveEndpoint$$anonfun$1.apply(BlockManagerSlaveEndpoint.scala:82)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1160)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.lang.Thread.run(Thread.java:811)
18/07/13 05:15:55 INFO cluster.ego.EGOFineGrainedSchedulerBackend: Spark driver enters idle mode
18/07/13 05:15:55 INFO cluster.ego.EGODeployScheduler: Spark context stopped.
18/07/13 05:15:55 INFO apache.spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
18/07/13 05:15:55 INFO storage.memory.MemoryStore: MemoryStore cleared
18/07/13 05:15:55 INFO spark.storage.BlockManager: BlockManager stopped
18/07/13 05:15:55 INFO spark.storage.BlockManagerMaster: BlockManagerMaster stopped
18/07/13 05:15:55 INFO spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
18/07/13 05:15:55 INFO apache.spark.SparkContext: Successfully stopped SparkContext
18/07/13 05:15:55 INFO spark.util.ShutdownHookManager: Shutdown hook called
18/07/13 05:15:55 INFO spark.util.ShutdownHookManager: Deleting directory /tmp/spark-21-ego-master/work/spark-ce4bd356-1214-4865-a7d4-8b9abf2b63d9
18/07/13 05:15:55 INFO deploy.ego.EGOClusterDriverWrapper: staging dir is None
18/07/13 05:15:55 INFO deploy.ego.EGOClusterDriverWrapper: Deleting local temp file /tmp/spark-21-ego-master/work/spark-driver-c2f2b275-5d12-4a36-b112-61dcb34a6935/simpleloanvalidationsparkrunner-1.0-SNAPSHOT-withodmrt.jar: true
18/07/13 05:15:55 INFO deploy.ego.EGOClusterDriverWrapper: Deleting local temp file /tmp/spark-21-ego-master/work/spark-driver-c2f2b275-5d12-4a36-b112-61dcb34a6935: true
