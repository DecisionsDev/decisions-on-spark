{"nbformat_minor": 1, "cells": [{"source": "# Automate loan approvals with Business rules in Apache Spark and Scala\n\n### Automating at scale your business decisions in Apache Spark with IBM ODM 8.9.2\n\nThis Scala notebook shows you how to execute locally business rules in DSX and Apache Spark. \nYou'll learn how to call in Apache Spark a rule-based decision service. This decision service has been programmed with IBM Operational Decision Manager.  \n\nThis notebook puts in action a decision service named Miniloan that is part of the ODM tutorials. It determines with business rules whether a customer is eligible for a loan according to specific criteria. The criteria include the amount of the loan, the annual income of the borrower, and the duration of the loan.\n\nFirst we load an application data set that was captured as a CSV file. In scala we apply a map to this data set to automate a rule-based reasoning, in order to outcome a decision. The rule execution is performed locally in the Spark service. This notebook shows a complete Scala code that can execute any ruleset based on the public APIs.\n\nTo get the most out of this notebook, you should have some familiarity with the Scala programming language.\n\n## Contents \nThis notebook contains the following main sections:\n\n1. [Load the loan validation request dataset.](#loaddatatset)\n2. [Load the business rule execution and the simple loan application object model libraries.](#loadjars)\n3. [Import Scala packages.](#importpackages)\n4. [Implement a decision making function.](#implementDecisionServiceMap)\n5. [Execute the business rules to approve or reject the loan applications.](#executedecisions) \n6. [View the automated decisions.](#viewdecisions)\n7. [Summary and next steps.](#summary)  ", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"source": "<a id=\"accessdataset\"></a>\n## 1. Loading a loan application dataset file\nA data set of simple loan applications is already available. You load it in the Notebook through its url.", "cell_type": "markdown", "metadata": {"collapsed": true}}, {"source": "// @hidden_cell\nimport scala.sys.process._\n\n\"wget https://odmlibserver.mybluemix.net/data/miniloan/miniloan-requests-10K.csv\".!", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}, {"source": "val filename = \"miniloan-requests-10K.csv\"", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}, {"source": "This following code loads the 10 000 simple loan application dataset written in CSV format.", "cell_type": "markdown", "metadata": {}}, {"source": "val requestData = sc.textFile(filename)\nval requestDataCount = requestData.count\nprintln(s\"$requestDataCount loan requests read in a CVS format\")\nprintln(\"The first 5 requests:\")\nrequestData.take(20).foreach(println)", "cell_type": "code", "execution_count": 14, "outputs": [{"output_type": "stream", "name": "stdout", "text": "10000 loan requests read in a CVS format\nThe first 5 requests:\nJohn Doe, 550, 80000, 250000, 240, 0.05d\nJohn Woo, 540, 100000, 250000, 240, 0.05d\nPeter Woo, 540, 60000, 250000, 120, 0.05d\nPeter Woo, 540, 60000, 250000, 120, 0.07d\nJohn Doe, 550, 80000, 250000, 240, 0.05d\nJohn Woo, 540, 100000, 250000, 240, 0.05d\nPeter Woo, 540, 60000, 250000, 120, 0.05d\nPeter Woo, 540, 60000, 250000, 120, 0.07d\nJohn Doe, 550, 80000, 250000, 240, 0.05d\nJohn Woo, 540, 100000, 250000, 240, 0.05d\nPeter Woo, 540, 60000, 250000, 120, 0.05d\nPeter Woo, 540, 60000, 250000, 120, 0.07d\nJohn Doe, 550, 80000, 250000, 240, 0.05d\nJohn Woo, 540, 100000, 250000, 240, 0.05d\nPeter Woo, 540, 60000, 250000, 120, 0.05d\nPeter Woo, 540, 60000, 250000, 120, 0.07d\nJohn Doe, 550, 80000, 250000, 240, 0.05d\nJohn Woo, 540, 100000, 250000, 240, 0.05d\nPeter Woo, 540, 60000, 250000, 120, 0.05d\nPeter Woo, 540, 60000, 250000, 120, 0.07d\n"}], "metadata": {"scrolled": true}}, {"source": "<a id=\"loadjars\"></a>\n## 2. Add libraries for business rule execution and a loan application object model\nThe XXX refers to your object storage or other place where you make available these jars.\n\nAdd the following jars to execute the deployed decision service\n<il>\n<li>%AddJar https://XXX/j2ee_connector-1_5-fr.jar</li>\n<li>%AddJar https://XXX/jrules-engine.jar</li>\n<li>%AddJar https://XXX/jrules-res-execution.jar</li>\n</il>\n\nIn addition you need the Apache Jackson annotation lib\n<il>\n<li>%AddJar https://XXX/jackson-annotations-2.6.5.jar</li>\n</il>\n\nBusiness Rules apply on a Java executable Object Model packaged as a jar. We need these classes to create the decision requests, and to retreive the response from the rule engine.\n<il>\n<li>%AddJar https://XXX/miniloan-xom.jar</li>\n</il>", "cell_type": "markdown", "metadata": {}}, {"source": "// @hidden_cell\n// The urls below are accessible for an IBM internal usage only\n\n%AddJar https://XXX/j2ee_connector-1_5-fr.jar\n%AddJar https://XXX/jrules-engine.jar\n%AddJar https://XXX/jrules-res-execution.jar\n%AddJar https://XXX/jackson-annotations-2.6.5.jar -f\n\n//Loan Application eXecutable Object Model\n%AddJar https://XXX/miniloan-xom.jar -f\n\nprint(\"Your notebook is now ready to execute business rules to approve or reject loan applications\")", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}, {"source": "<a id=\"importpackages\"></a>\n## 3. Import packages\nImport ODM and Apache Spark packages.", "cell_type": "markdown", "metadata": {}}, {"source": "import java.util.Map\nimport java.util.HashMap\n\nimport com.fasterxml.jackson.core.JsonGenerationException\nimport com.fasterxml.jackson.core.JsonProcessingException\nimport com.fasterxml.jackson.databind.JsonMappingException\nimport com.fasterxml.jackson.databind.ObjectMapper\nimport com.fasterxml.jackson.databind.SerializationFeature\n\nimport org.apache.spark.SparkConf\nimport org.apache.spark.api.java.JavaDoubleRDD\nimport org.apache.spark.api.java.JavaRDD\nimport org.apache.spark.api.java.JavaSparkContext\nimport org.apache.spark.api.java.function.Function\nimport org.apache.hadoop.fs.FileSystem\nimport org.apache.hadoop.fs.Path\n\nimport scala.collection.JavaConverters._\n\nimport ilog.rules.res.model._\n\nimport com.ibm.res.InMemoryJ2SEFactory\nimport com.ibm.res.InMemoryRepositoryDAO\n\nimport ilog.rules.res.session._\n\nimport miniloan.Borrower\nimport miniloan.Loan\n\nimport scala.io.Source\nimport java.net.URL\nimport java.io.InputStream", "cell_type": "code", "execution_count": 16, "outputs": [], "metadata": {}}, {"source": "<a id=\"implementDecisionServiceMap\"></a>\n## 4. Implement a Map function that executes a rule-based decision service", "cell_type": "markdown", "metadata": {}}, {"source": "case class MiniLoanRequest(borrower: miniloan.Borrower, \n      loan: miniloan.Loan) \n\ncase class RESRunner(sessionFactory: com.ibm.res.InMemoryJ2SEFactory)  {\n    \n  def executeAsString(s: String): String = {\n    println(\"executeAsString\")\n    val request = makeRequest(s)\n    val response = executeRequest(request)\n    \n    response\n  }\n  \n   private def makeRequest(s: String): MiniLoanRequest = {\n    val tokens = s.split(\",\")\n       \n    // Borrower deserialization from CSV\n    val borrowerName = tokens(0)\n    val borrowerCreditScore = java.lang.Integer.parseInt(tokens(1).trim())\n    val borrowerYearlyIncome = java.lang.Integer.parseInt(tokens(2).trim())\n    val loanAmount = java.lang.Integer.parseInt(tokens(3).trim())\n    val loanDuration = java.lang.Integer.parseInt(tokens(4).trim())\n    val yearlyInterestRate = java.lang.Double.parseDouble(tokens(5).trim())\n    val borrower = new miniloan.Borrower(borrowerName, borrowerCreditScore, borrowerYearlyIncome)\n       \n    // Loan request deserialization from CSV\n    val loan = new miniloan.Loan()\n    loan.setAmount(loanAmount)\n    loan.setDuration(loanDuration)\n    loan.setYearlyInterestRate(yearlyInterestRate)\n       \n    val request = new MiniLoanRequest(borrower, loan)\n    request\n  }\n    \n def executeRequest(request: MiniLoanRequest): String = {\n    try {\n        val sessionRequest = sessionFactory.createRequest()\n        val rulesetPath = \"/Miniloan/Miniloan\"\n        sessionRequest.setRulesetPath(ilog.rules.res.model.IlrPath.parsePath(rulesetPath))\n\n        //sessionRequest.getTraceFilter.setInfoAllFilters(false)\n        val inputParameters = sessionRequest.getInputParameters\n        inputParameters.put(\"loan\", request.loan)\n        inputParameters.put(\"borrower\", request.borrower)\n        val session = sessionFactory.createStatelessSession()\n        \n        val response = session.execute(sessionRequest)\n        \n        var loan = response.getOutputParameters().get(\"loan\").asInstanceOf[miniloan.Loan]\n        val mapper = new com.fasterxml.jackson.databind.ObjectMapper()\n        mapper.configure(com.fasterxml.jackson.databind.SerializationFeature.FAIL_ON_EMPTY_BEANS, false)\n        val results = new java.util.HashMap[String,Object]()\n        results.put(\"input\", inputParameters)\n        results.put(\"output\", response.getOutputParameters())\n        try {\n            //return mapper.writeValueAsString(results)\n            return mapper.writerWithDefaultPrettyPrinter().writeValueAsString(results);\n        } catch {\n            case e: Exception => return e.toString()\n        }\n        \"Error\"\n    } catch {\n        case exception: Exception => {\n            return exception.toString()\n        }\n    }\n    \"Error\"\n  }\n}\n\n\nval decisionService = new Function[String, String]() {\n\n    @transient private var ruleSessionFactory: InMemoryJ2SEFactory = null\n    private val rulesetURL = \"https://odmlibserver.mybluemix.net/8901/decisionservices/miniloan-8901.dsar\"\n    @transient private var rulesetStream: InputStream = null\n\n  def GetRuleSessionFactory(): InMemoryJ2SEFactory = {\n    if (ruleSessionFactory == null) {\n      ruleSessionFactory = new InMemoryJ2SEFactory()\n      // Create the Management Session \n      var repositoryFactory = ruleSessionFactory.createManagementSession().getRepositoryFactory()\n      var repository = repositoryFactory.createRepository()\n  \n      // Deploy the Ruleapp with the Regular Management Session API.\n      var rapp = repositoryFactory.createRuleApp(\"Miniloan\", IlrVersion.parseVersion(\"1.0\"));\n      var rs = repositoryFactory.createRuleset(\"Miniloan\",IlrVersion.parseVersion(\"1.1\"));\n      rapp.addRuleset(rs);\n        \n      //var fileStream = Source.fromResourceAsStream(RulesetFileName)\n\n      rulesetStream = new java.net.URL(rulesetURL).openStream()\n\n      rs.setRESRulesetArchive(IlrEngineType.DE,rulesetStream)\n      repository.addRuleApp(rapp)\n    \n    }\n    ruleSessionFactory\n  }\n    \n  def call(s: String): String = {\n    var runner = new RESRunner(GetRuleSessionFactory())\n    return runner.executeAsString(s)\n  }\n    \n  def execute(s: String): String = {\n    try {\n      var runner = new RESRunner(GetRuleSessionFactory())\n      return runner.executeAsString(s)\n    } catch {\n      case exception: Exception => {\n        exception.printStackTrace(System.err)\n      }\n    }\n    \"Execution error\"\n  }\n}", "cell_type": "code", "execution_count": 17, "outputs": [], "metadata": {}}, {"source": "<a id=\"executedecisions\"></a>\n## 5. Automate the decision making on the loan application dataset\nYou invoke a map on the decision function. While the map occurs rule engines are processing in parallel the loan applications to produce a data set of answers.", "cell_type": "markdown", "metadata": {}}, {"source": "println(\"Start of Execution\")\nval answers = requestData.map(decisionService.execute)\nprintf(\"Number of rule based decisions: %s \\n\" , answers.count)\n// Cleanup output file\n//val fs = FileSystem.get(new URI(outputPath), sc.hadoopConfiguration);\n//if (fs.exists(new Path(outputPath)))\n   // fs.delete(new Path(outputPath), true)\n// Save RDD in a HDFS file\nprintln(\"End of Execution \")\n//answers.saveAsTextFile(\"swift://DecisionBatchExecution.\" + securedAccessName + \"/miniloan-decisions-10.csv\")\n\nprintln(\"Decision automation job done\")", "cell_type": "code", "execution_count": 18, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Start of Execution\nNumber of rule based decisions: 10000                                           \nEnd of Execution \nDecision automation job done\n"}], "metadata": {}}, {"source": "<a id=\"viewdecisions\"></a>\n## 6. View your automated decisions\nEach decision is composed of output parameters and of a decision trace. The loan data contains the approval flag and the computed yearly repayment. The decision trace lists the business rules that have been executed in sequence to come to the conclusion. Each decision has been serialized in JSON.", "cell_type": "markdown", "metadata": {}}, {"source": "//answers.toDF().show(false)\nanswers.take(1).foreach(println)", "cell_type": "code", "execution_count": 19, "outputs": [{"output_type": "stream", "name": "stdout", "text": "{\n  \"output\" : {\n    \"ilog.rules.firedRulesCount\" : 0,\n    \"loan\" : {\n      \"amount\" : 250000,\n      \"duration\" : 240,\n      \"yearlyInterestRate\" : 0.05,\n      \"yearlyRepayment\" : 19798,\n      \"approved\" : true,\n      \"messages\" : [ ]\n    }\n  },\n  \"input\" : {\n    \"loan\" : {\n      \"amount\" : 250000,\n      \"duration\" : 240,\n      \"yearlyInterestRate\" : 0.05,\n      \"yearlyRepayment\" : 19798,\n      \"approved\" : true,\n      \"messages\" : [ ]\n    },\n    \"borrower\" : {\n      \"name\" : \"John Doe\",\n      \"creditScore\" : 550,\n      \"yearlyIncome\" : 80000\n    }\n  }\n}\n"}], "metadata": {}}, {"source": "<a id=\"summary\"></a>\n## 7. Summary and next steps\nCongratulations! You have applied business rules to automatically determine loan approval eligibility. You loaded a loan application data set, ran a rule engine inside an Apache Spark cluster to make an eligibility decision for each applicant. Each decision is a Scala object that is part of a Spark Resilient Data Set. \nEach decision is structured with input parameters (the context of the decision) and output parameters. For audit purpose the rule engine can emit a decision trace.\n\nDisclaimer: this notebook uses an experimental in memory RuleSession API that simplifies the deployment pattern. For a customer deployment you have to use a Rule Execution Server database to store the rule set. At execution time the Apache Spark application loads and run the rules through regular JSE RuleSession API. \n\nIn both cases (regular database or experimental in memory) ODM empowers rule engine to automate decisions in parallel locally in the Spark cluster giving high scalability.\n\n<a id=\"authors\"></a>\n## Authors\nPierre Feillet and Laurent Grateau are business rule engineers at IBM working in the Decision lab located in France.\n\nCopyright \u00a9 2018 IBM. This notebook and its source code are released under the terms of the MIT License.", "cell_type": "markdown", "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Scala 2.11 with Spark 2.1", "name": "scala-spark21", "language": "scala"}, "language_info": {"mimetype": "text/x-scala", "version": "2.11.8", "name": "scala", "pygments_lexer": "scala", "file_extension": ".scala", "codemirror_mode": "text/x-scala"}}}